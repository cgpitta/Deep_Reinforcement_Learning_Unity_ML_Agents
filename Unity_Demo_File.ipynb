{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea96626-7f38-4546-bb1c-70d598f60c34",
   "metadata": {},
   "source": [
    "#### Run this notebook from the same virtual environment where you run the ml-agents training command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559eceb5-2f7f-4227-9ca5-1eb4b563b96f",
   "metadata": {},
   "source": [
    "#### This is a demo notebook created to run the baseline and optimal configurations from my Hallway & Pyramids Experiments\n",
    "Note: You must have Unity Hub & ML Agents Installed In Order to Run the Notebook\n",
    "These commands can also be run through the command line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c408b2f7-8424-408a-a832-106fa111cdd2",
   "metadata": {},
   "source": [
    "#### Unity Hub & Environment Installation/Setup Instructions\n",
    "*\tUnity Hub is the Project and Editor Manager for Unity (Windows Side)\n",
    "    * Project Launcher: ML-Agents sample environments are Unity projects. Unity Hub is the tool that opens and manages them\n",
    "    *\tVersion Control: Different ML Agents releases often require specific Unity editor versions. Hub lets you install and switch between multiple versions seamlessly.\n",
    "* Installation Instructions:\n",
    "* Download Hub From https://unity.com/download\n",
    "    * Once you download and install has been completed, open the Hub and create a Unity Account (its free)\n",
    "    * Note: My Unity Hub/Editor are installed on Windows but I ran my ML-Agents Training from an Ubuntu Virtual Environment to use my GPU\n",
    "    * From the Hub, navigate to ‘Installs’, select “Editor’, and ensure the Latest LTS is installed\n",
    "    * o\tNote: My Unity Hub is downloaded for Windows while Unity ML Agents was run via Ubuntu Virtual Environment\n",
    "\n",
    "* From Windows Powershell into folder that Unity can access (Unity Side)\n",
    "    * Clone git clone https://github.com/Unity-Technologies/ml-agents.git \n",
    "\n",
    "* From Unity Hub, select “Add” from the ‘Projects’ tab followed by ‘Add project from disk’\n",
    "    * Locate the folder that you cloned the github repo to \n",
    "    * Open ml-agents ->Project\n",
    "    * The Project should appear under your Projects list (open it)\n",
    "    * Open Package Manager from Windows and Locate ML-Agents under ‘Unity Registry’ to confirm that it is installed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cb0cc-f980-4059-a3b0-b4c9c7c01437",
   "metadata": {},
   "source": [
    "#### Python Side: Installing TensorFlow and the ML-Agents Training Toolkit\n",
    "\n",
    "* Create Virtual Environment: conda create -n unity-ml python=3.9\n",
    "    * Note: Python 3.8-3.10 is compatible with the current ML-Agents versions\n",
    "* Activate the Virtual Environment and install required packages\n",
    "    * pip install mlagents\n",
    "    * Note: Do Not install the latest version of TensorFlow in this environment\n",
    "    * The mlagents package will install its required deep learning dependencies (PyTorch and its associated libraries). Confirm successful installation and no dependency resolution errors are reported\n",
    "    * From ubuntu, test that you can start a training run with \n",
    "mlagents-learn ~/ml-agents-config/ppo/3DBall.yaml --run-id=TestRun1 –train\n",
    "* Troubleshooting Errors that I ran Into:\n",
    "    * Error 1: Protobuf Downgrade Error\n",
    "        * Resolved With: pip install protobuf==3.20.3\n",
    "    * Error 2: Missing ‘six’ module\n",
    "        * Resolved with: pip install six\n",
    "    * Error 3: Version Conflicts Between Cuda/ML-Agents/PyTorch because I have NVIDIA GeForce RTX 4070 Laptop GPU GPU\n",
    "        * Resolved With: pip install torch==1.11.0+cu115 torchvision==0.12.0+cu115 torchaudio==0.11.0 --index-url https://download.pytorch.org/whl/cu115\n",
    "* Once you can successfully run the training command from ubuntu, go back to your opened project in Unity Editor\n",
    "    * Under Assets, open ML-Agents -> Examples – Scenes -> 3DBall\n",
    "    * Hit ‘Play’ at the top\n",
    "* ctrl + c ends a training run early but 3DBall runs very vast so its a example environment to familarize yourself with the platform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc8ab3c-68d1-47fd-a536-49582ce12ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorboard as tb\n",
    "import yaml\n",
    "import subprocess\n",
    "import os\n",
    "import struct\n",
    "import mlagents\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af700b7d-2373-4df3-b136-fbedc36622bc",
   "metadata": {},
   "source": [
    "##### Before running a training, open your Project and the Respective Scene (Hallway or Pyramids) in Unity Editor \n",
    "##### Once you run the command to kick off a training run, go to Unity Editor and hit play when instructed to in Jupyter Notebook\n",
    "##### You must let the training complete before kicking off a new training\n",
    "##### To monitor the results, open the 'Unity_Demo_Dashboards' notebook and run the results cell for the training you are running \n",
    "##### Note, due to numpy versioning issues between TensorFlow & ML-Agents, the Unity_Demo_Dashboards notebook should be run from a virtual environment with TensorFlow installed in it. This environment should not have ML-Agents Installed In It! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9c304-214b-4222-a2ea-15429b48d2a7",
   "metadata": {},
   "source": [
    "#All statements can be run from the command line. When running from jupyter notebook, some of the dashboard code won't run until the job finishes so you can't entirely monitor in real time. To monitor the training in real time, run the below kickoff statements from the command line in your virtual environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b57d6-1b26-4d84-bd53-36036ece9187",
   "metadata": {},
   "source": [
    "### Hallway Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72176de-96c2-4005-b463-18815052d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill -9 mlagents-learn 2>/dev/null\n",
    "!sleep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204bb068-93e7-4116-b64e-e88350595bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.30.0,\n",
      "  ml-agents-envs: 0.30.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 1.8.1+cu111\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: Hallway?team=0\n",
      "[WARNING] Deleting TensorBoard data events.out.tfevents.1765686420.CPitta83.7524.0 that was left over from a previous run.\n",
      "2025-12-15 22:11:15.797810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
      "[INFO] Hyperparameters for behavior name Hallway: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t1024\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.03\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\t\n",
      "\t    sequence_length:\t64\n",
      "\t    memory_size:\t128\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tmax_steps:\t7000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Hallway. Step: 10000. Time Elapsed: 36.328 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 20000. Time Elapsed: 45.030 s. Mean Reward: -0.969. Std of Reward: 0.123. Training.\n",
      "[INFO] Hallway. Step: 30000. Time Elapsed: 53.562 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 40000. Time Elapsed: 62.225 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 50000. Time Elapsed: 70.500 s. Mean Reward: -0.961. Std of Reward: 0.157. Training.\n",
      "[INFO] Hallway. Step: 60000. Time Elapsed: 78.709 s. Mean Reward: -0.923. Std of Reward: 0.306. Training.\n",
      "[INFO] Hallway. Step: 70000. Time Elapsed: 87.474 s. Mean Reward: -0.925. Std of Reward: 0.310. Training.\n",
      "[INFO] Hallway. Step: 80000. Time Elapsed: 96.165 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 90000. Time Elapsed: 104.694 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 100000. Time Elapsed: 112.765 s. Mean Reward: -0.979. Std of Reward: 0.084. Training.\n",
      "[INFO] Hallway. Step: 110000. Time Elapsed: 121.249 s. Mean Reward: -1.000. Std of Reward: 0.001. Training.\n",
      "[INFO] Hallway. Step: 120000. Time Elapsed: 130.124 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 130000. Time Elapsed: 138.227 s. Mean Reward: -0.384. Std of Reward: 0.711. Training.\n",
      "[INFO] Hallway. Step: 140000. Time Elapsed: 147.524 s. Mean Reward: -0.011. Std of Reward: 0.641. Training.\n",
      "[INFO] Hallway. Step: 150000. Time Elapsed: 156.503 s. Mean Reward: 0.047. Std of Reward: 0.677. Training.\n",
      "[INFO] Hallway. Step: 160000. Time Elapsed: 165.706 s. Mean Reward: 0.119. Std of Reward: 0.581. Training.\n",
      "[INFO] Hallway. Step: 170000. Time Elapsed: 175.165 s. Mean Reward: 0.264. Std of Reward: 0.540. Training.\n",
      "[INFO] Hallway. Step: 180000. Time Elapsed: 185.021 s. Mean Reward: 0.272. Std of Reward: 0.587. Training.\n",
      "[INFO] Hallway. Step: 190000. Time Elapsed: 195.114 s. Mean Reward: 0.269. Std of Reward: 0.557. Training.\n",
      "[INFO] Hallway. Step: 200000. Time Elapsed: 205.583 s. Mean Reward: 0.380. Std of Reward: 0.542. Training.\n",
      "[INFO] Hallway. Step: 210000. Time Elapsed: 215.912 s. Mean Reward: 0.324. Std of Reward: 0.559. Training.\n",
      "[INFO] Hallway. Step: 220000. Time Elapsed: 226.259 s. Mean Reward: 0.410. Std of Reward: 0.537. Training.\n",
      "[INFO] Hallway. Step: 230000. Time Elapsed: 236.392 s. Mean Reward: 0.293. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 240000. Time Elapsed: 246.516 s. Mean Reward: 0.327. Std of Reward: 0.558. Training.\n",
      "[INFO] Hallway. Step: 250000. Time Elapsed: 256.500 s. Mean Reward: 0.279. Std of Reward: 0.558. Training.\n",
      "[INFO] Hallway. Step: 260000. Time Elapsed: 266.676 s. Mean Reward: 0.377. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 270000. Time Elapsed: 276.824 s. Mean Reward: 0.410. Std of Reward: 0.544. Training.\n",
      "[INFO] Hallway. Step: 280000. Time Elapsed: 286.967 s. Mean Reward: 0.315. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 290000. Time Elapsed: 297.122 s. Mean Reward: 0.303. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 300000. Time Elapsed: 307.501 s. Mean Reward: 0.291. Std of Reward: 0.541. Training.\n",
      "[INFO] Hallway. Step: 310000. Time Elapsed: 317.600 s. Mean Reward: 0.363. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 320000. Time Elapsed: 328.111 s. Mean Reward: 0.363. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 330000. Time Elapsed: 338.408 s. Mean Reward: 0.453. Std of Reward: 0.540. Training.\n",
      "[INFO] Hallway. Step: 340000. Time Elapsed: 349.130 s. Mean Reward: 0.357. Std of Reward: 0.557. Training.\n",
      "[INFO] Hallway. Step: 350000. Time Elapsed: 359.292 s. Mean Reward: 0.370. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 360000. Time Elapsed: 369.664 s. Mean Reward: 0.367. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 370000. Time Elapsed: 379.906 s. Mean Reward: 0.363. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 380000. Time Elapsed: 390.009 s. Mean Reward: 0.266. Std of Reward: 0.536. Training.\n",
      "[INFO] Hallway. Step: 390000. Time Elapsed: 399.972 s. Mean Reward: 0.338. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 400000. Time Elapsed: 410.069 s. Mean Reward: 0.317. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 410000. Time Elapsed: 420.432 s. Mean Reward: 0.321. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 420000. Time Elapsed: 430.502 s. Mean Reward: 0.385. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 430000. Time Elapsed: 440.493 s. Mean Reward: 0.201. Std of Reward: 0.541. Training.\n",
      "[INFO] Hallway. Step: 440000. Time Elapsed: 450.685 s. Mean Reward: 0.362. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 450000. Time Elapsed: 461.289 s. Mean Reward: 0.272. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 460000. Time Elapsed: 472.263 s. Mean Reward: 0.260. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 470000. Time Elapsed: 482.523 s. Mean Reward: 0.163. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 480000. Time Elapsed: 493.636 s. Mean Reward: 0.361. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 490000. Time Elapsed: 504.298 s. Mean Reward: 0.333. Std of Reward: 0.560. Training.\n",
      "[INFO] Hallway. Step: 500000. Time Elapsed: 515.328 s. Mean Reward: 0.371. Std of Reward: 0.551. Training.\n",
      "/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:1941: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n",
      "[INFO] Exported results/hallway_baseline1/Hallway/Hallway-499999.onnx\n",
      "[INFO] Hallway. Step: 510000. Time Elapsed: 526.031 s. Mean Reward: 0.383. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 520000. Time Elapsed: 536.263 s. Mean Reward: 0.384. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 530000. Time Elapsed: 547.487 s. Mean Reward: 0.339. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 540000. Time Elapsed: 558.037 s. Mean Reward: 0.298. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 550000. Time Elapsed: 568.441 s. Mean Reward: 0.252. Std of Reward: 0.543. Training.\n",
      "[INFO] Hallway. Step: 560000. Time Elapsed: 579.385 s. Mean Reward: 0.304. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 570000. Time Elapsed: 590.257 s. Mean Reward: 0.394. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 580000. Time Elapsed: 600.666 s. Mean Reward: 0.346. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 590000. Time Elapsed: 611.680 s. Mean Reward: 0.266. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 600000. Time Elapsed: 621.934 s. Mean Reward: 0.401. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 610000. Time Elapsed: 632.451 s. Mean Reward: 0.357. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 620000. Time Elapsed: 642.508 s. Mean Reward: 0.389. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 630000. Time Elapsed: 653.282 s. Mean Reward: 0.440. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 640000. Time Elapsed: 664.057 s. Mean Reward: 0.346. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 650000. Time Elapsed: 674.404 s. Mean Reward: 0.363. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 660000. Time Elapsed: 685.126 s. Mean Reward: 0.350. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 670000. Time Elapsed: 696.277 s. Mean Reward: 0.370. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 680000. Time Elapsed: 706.738 s. Mean Reward: 0.379. Std of Reward: 0.559. Training.\n",
      "[INFO] Hallway. Step: 690000. Time Elapsed: 717.073 s. Mean Reward: 0.394. Std of Reward: 0.558. Training.\n",
      "[INFO] Hallway. Step: 700000. Time Elapsed: 727.651 s. Mean Reward: 0.308. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 710000. Time Elapsed: 738.285 s. Mean Reward: 0.448. Std of Reward: 0.539. Training.\n",
      "[INFO] Hallway. Step: 720000. Time Elapsed: 749.177 s. Mean Reward: 0.278. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 730000. Time Elapsed: 760.387 s. Mean Reward: 0.310. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 740000. Time Elapsed: 771.239 s. Mean Reward: 0.307. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 750000. Time Elapsed: 782.344 s. Mean Reward: 0.399. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 760000. Time Elapsed: 793.392 s. Mean Reward: 0.400. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 770000. Time Elapsed: 804.572 s. Mean Reward: 0.359. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 780000. Time Elapsed: 815.923 s. Mean Reward: 0.374. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 790000. Time Elapsed: 826.833 s. Mean Reward: 0.301. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 800000. Time Elapsed: 837.981 s. Mean Reward: 0.370. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 810000. Time Elapsed: 850.014 s. Mean Reward: 0.416. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 820000. Time Elapsed: 863.002 s. Mean Reward: 0.384. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 830000. Time Elapsed: 875.385 s. Mean Reward: 0.340. Std of Reward: 0.557. Training.\n",
      "[INFO] Hallway. Step: 840000. Time Elapsed: 887.889 s. Mean Reward: 0.357. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 850000. Time Elapsed: 900.661 s. Mean Reward: 0.396. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 860000. Time Elapsed: 912.610 s. Mean Reward: 0.353. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 870000. Time Elapsed: 923.941 s. Mean Reward: 0.352. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 880000. Time Elapsed: 934.284 s. Mean Reward: 0.317. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 890000. Time Elapsed: 944.702 s. Mean Reward: 0.258. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 900000. Time Elapsed: 955.184 s. Mean Reward: 0.380. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 910000. Time Elapsed: 965.858 s. Mean Reward: 0.402. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 920000. Time Elapsed: 977.099 s. Mean Reward: 0.329. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 930000. Time Elapsed: 987.928 s. Mean Reward: 0.312. Std of Reward: 0.543. Training.\n",
      "[INFO] Hallway. Step: 940000. Time Elapsed: 998.921 s. Mean Reward: 0.391. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 950000. Time Elapsed: 1009.404 s. Mean Reward: 0.326. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 960000. Time Elapsed: 1020.284 s. Mean Reward: 0.374. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 970000. Time Elapsed: 1031.261 s. Mean Reward: 0.362. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 980000. Time Elapsed: 1042.258 s. Mean Reward: 0.378. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 990000. Time Elapsed: 1052.663 s. Mean Reward: 0.391. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1000000. Time Elapsed: 1063.425 s. Mean Reward: 0.265. Std of Reward: 0.549. Training.\n",
      "[INFO] Exported results/hallway_baseline1/Hallway/Hallway-999960.onnx\n",
      "[INFO] Hallway. Step: 1010000. Time Elapsed: 1073.836 s. Mean Reward: 0.299. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 1020000. Time Elapsed: 1084.829 s. Mean Reward: 0.450. Std of Reward: 0.544. Training.\n",
      "[INFO] Hallway. Step: 1030000. Time Elapsed: 1096.070 s. Mean Reward: 0.331. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 1040000. Time Elapsed: 1106.684 s. Mean Reward: 0.358. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1050000. Time Elapsed: 1117.378 s. Mean Reward: 0.382. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 1060000. Time Elapsed: 1128.015 s. Mean Reward: 0.356. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1070000. Time Elapsed: 1137.957 s. Mean Reward: 0.366. Std of Reward: 0.558. Training.\n",
      "[INFO] Hallway. Step: 1080000. Time Elapsed: 1148.512 s. Mean Reward: 0.378. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1090000. Time Elapsed: 1159.875 s. Mean Reward: 0.323. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1100000. Time Elapsed: 1170.773 s. Mean Reward: 0.284. Std of Reward: 0.544. Training.\n",
      "[INFO] Hallway. Step: 1110000. Time Elapsed: 1181.990 s. Mean Reward: 0.346. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1120000. Time Elapsed: 1193.510 s. Mean Reward: 0.400. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1130000. Time Elapsed: 1204.443 s. Mean Reward: 0.370. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1140000. Time Elapsed: 1215.133 s. Mean Reward: 0.380. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1150000. Time Elapsed: 1225.814 s. Mean Reward: 0.358. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1160000. Time Elapsed: 1236.586 s. Mean Reward: 0.282. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1170000. Time Elapsed: 1246.966 s. Mean Reward: 0.352. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1180000. Time Elapsed: 1257.997 s. Mean Reward: 0.380. Std of Reward: 0.558. Training.\n",
      "[INFO] Hallway. Step: 1190000. Time Elapsed: 1269.118 s. Mean Reward: 0.323. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1200000. Time Elapsed: 1279.932 s. Mean Reward: 0.327. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1210000. Time Elapsed: 1290.466 s. Mean Reward: 0.355. Std of Reward: 0.557. Training.\n",
      "[INFO] Hallway. Step: 1220000. Time Elapsed: 1301.961 s. Mean Reward: 0.369. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1230000. Time Elapsed: 1312.867 s. Mean Reward: 0.305. Std of Reward: 0.543. Training.\n",
      "[INFO] Hallway. Step: 1240000. Time Elapsed: 1324.091 s. Mean Reward: 0.344. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 1250000. Time Elapsed: 1334.821 s. Mean Reward: 0.366. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 1260000. Time Elapsed: 1345.944 s. Mean Reward: 0.403. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1270000. Time Elapsed: 1357.451 s. Mean Reward: 0.414. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1280000. Time Elapsed: 1368.526 s. Mean Reward: 0.393. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1290000. Time Elapsed: 1379.009 s. Mean Reward: 0.361. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 1300000. Time Elapsed: 1389.361 s. Mean Reward: 0.428. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1310000. Time Elapsed: 1399.752 s. Mean Reward: 0.343. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 1320000. Time Elapsed: 1409.909 s. Mean Reward: 0.355. Std of Reward: 0.557. Training.\n",
      "[INFO] Hallway. Step: 1330000. Time Elapsed: 1420.904 s. Mean Reward: 0.294. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1340000. Time Elapsed: 1431.648 s. Mean Reward: 0.343. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 1350000. Time Elapsed: 1442.412 s. Mean Reward: 0.424. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 1360000. Time Elapsed: 1453.807 s. Mean Reward: 0.333. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1370000. Time Elapsed: 1464.968 s. Mean Reward: 0.342. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1380000. Time Elapsed: 1475.827 s. Mean Reward: 0.411. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 1390000. Time Elapsed: 1486.591 s. Mean Reward: 0.367. Std of Reward: 0.559. Training.\n",
      "[INFO] Hallway. Step: 1400000. Time Elapsed: 1497.610 s. Mean Reward: 0.355. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 1410000. Time Elapsed: 1508.815 s. Mean Reward: 0.397. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1420000. Time Elapsed: 1519.458 s. Mean Reward: 0.398. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1430000. Time Elapsed: 1529.944 s. Mean Reward: 0.388. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1440000. Time Elapsed: 1541.157 s. Mean Reward: 0.406. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1450000. Time Elapsed: 1552.641 s. Mean Reward: 0.319. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1460000. Time Elapsed: 1563.403 s. Mean Reward: 0.427. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1470000. Time Elapsed: 1574.487 s. Mean Reward: 0.401. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1480000. Time Elapsed: 1585.420 s. Mean Reward: 0.363. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1490000. Time Elapsed: 1598.374 s. Mean Reward: 0.405. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1500000. Time Elapsed: 1611.408 s. Mean Reward: 0.351. Std of Reward: 0.551. Training.\n",
      "[INFO] Exported results/hallway_baseline1/Hallway/Hallway-1499986.onnx\n",
      "[INFO] Hallway. Step: 1510000. Time Elapsed: 1624.381 s. Mean Reward: 0.405. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1520000. Time Elapsed: 1636.776 s. Mean Reward: 0.479. Std of Reward: 0.543. Training.\n",
      "[INFO] Hallway. Step: 1530000. Time Elapsed: 1649.502 s. Mean Reward: 0.352. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1540000. Time Elapsed: 1661.150 s. Mean Reward: 0.295. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 1550000. Time Elapsed: 1673.409 s. Mean Reward: 0.406. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 1560000. Time Elapsed: 1686.352 s. Mean Reward: 0.386. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 1570000. Time Elapsed: 1698.273 s. Mean Reward: 0.392. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1580000. Time Elapsed: 1710.615 s. Mean Reward: 0.362. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1590000. Time Elapsed: 1723.432 s. Mean Reward: 0.402. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1600000. Time Elapsed: 1736.458 s. Mean Reward: 0.342. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1610000. Time Elapsed: 1749.521 s. Mean Reward: 0.422. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1620000. Time Elapsed: 1761.267 s. Mean Reward: 0.397. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1630000. Time Elapsed: 1772.269 s. Mean Reward: 0.383. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1640000. Time Elapsed: 1783.328 s. Mean Reward: 0.365. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1650000. Time Elapsed: 1794.612 s. Mean Reward: 0.373. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1660000. Time Elapsed: 1805.315 s. Mean Reward: 0.336. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1670000. Time Elapsed: 1815.318 s. Mean Reward: 0.360. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1680000. Time Elapsed: 1827.127 s. Mean Reward: 0.341. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1690000. Time Elapsed: 1838.312 s. Mean Reward: 0.393. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1700000. Time Elapsed: 1849.718 s. Mean Reward: 0.404. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1710000. Time Elapsed: 1861.693 s. Mean Reward: 0.296. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 1720000. Time Elapsed: 1873.352 s. Mean Reward: 0.346. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1730000. Time Elapsed: 1884.524 s. Mean Reward: 0.307. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 1740000. Time Elapsed: 1896.059 s. Mean Reward: 0.345. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1750000. Time Elapsed: 1907.380 s. Mean Reward: 0.382. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 1760000. Time Elapsed: 1918.502 s. Mean Reward: 0.393. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 1770000. Time Elapsed: 1930.245 s. Mean Reward: 0.367. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1780000. Time Elapsed: 1941.722 s. Mean Reward: 0.394. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1790000. Time Elapsed: 1954.189 s. Mean Reward: 0.365. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1800000. Time Elapsed: 1966.177 s. Mean Reward: 0.371. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1810000. Time Elapsed: 1977.516 s. Mean Reward: 0.294. Std of Reward: 0.542. Training.\n",
      "[INFO] Hallway. Step: 1820000. Time Elapsed: 1989.666 s. Mean Reward: 0.385. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1830000. Time Elapsed: 2001.341 s. Mean Reward: 0.427. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 1840000. Time Elapsed: 2012.362 s. Mean Reward: 0.354. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 1850000. Time Elapsed: 2023.223 s. Mean Reward: 0.393. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1860000. Time Elapsed: 2034.901 s. Mean Reward: 0.316. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1870000. Time Elapsed: 2046.685 s. Mean Reward: 0.335. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1880000. Time Elapsed: 2058.509 s. Mean Reward: 0.337. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 1890000. Time Elapsed: 2069.845 s. Mean Reward: 0.377. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1900000. Time Elapsed: 2082.021 s. Mean Reward: 0.409. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1910000. Time Elapsed: 2094.285 s. Mean Reward: 0.324. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1920000. Time Elapsed: 2106.687 s. Mean Reward: 0.362. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 1930000. Time Elapsed: 2117.481 s. Mean Reward: 0.384. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 1940000. Time Elapsed: 2129.038 s. Mean Reward: 0.356. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1950000. Time Elapsed: 2140.573 s. Mean Reward: 0.343. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 1960000. Time Elapsed: 2152.110 s. Mean Reward: 0.389. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1970000. Time Elapsed: 2163.938 s. Mean Reward: 0.329. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 1980000. Time Elapsed: 2174.881 s. Mean Reward: 0.358. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 1990000. Time Elapsed: 2186.371 s. Mean Reward: 0.353. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 2000000. Time Elapsed: 2197.645 s. Mean Reward: 0.318. Std of Reward: 0.549. Training.\n",
      "[INFO] Exported results/hallway_baseline1/Hallway/Hallway-1999984.onnx\n",
      "[INFO] Hallway. Step: 2010000. Time Elapsed: 2209.069 s. Mean Reward: 0.371. Std of Reward: 0.544. Training.\n",
      "[INFO] Hallway. Step: 2020000. Time Elapsed: 2220.115 s. Mean Reward: 0.361. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 2030000. Time Elapsed: 2231.741 s. Mean Reward: 0.272. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 2040000. Time Elapsed: 2243.270 s. Mean Reward: 0.374. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2050000. Time Elapsed: 2254.812 s. Mean Reward: 0.413. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 2060000. Time Elapsed: 2266.624 s. Mean Reward: 0.283. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 2070000. Time Elapsed: 2277.733 s. Mean Reward: 0.326. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2080000. Time Elapsed: 2289.288 s. Mean Reward: 0.314. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 2090000. Time Elapsed: 2301.269 s. Mean Reward: 0.366. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2100000. Time Elapsed: 2312.754 s. Mean Reward: 0.420. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 2110000. Time Elapsed: 2324.316 s. Mean Reward: 0.320. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 2120000. Time Elapsed: 2335.554 s. Mean Reward: 0.351. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 2130000. Time Elapsed: 2347.216 s. Mean Reward: 0.353. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 2140000. Time Elapsed: 2359.549 s. Mean Reward: 0.354. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 2150000. Time Elapsed: 2370.956 s. Mean Reward: 0.384. Std of Reward: 0.553. Training.\n",
      "[INFO] Hallway. Step: 2160000. Time Elapsed: 2382.254 s. Mean Reward: 0.351. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2170000. Time Elapsed: 2395.051 s. Mean Reward: 0.411. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2180000. Time Elapsed: 2407.108 s. Mean Reward: 0.395. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 2190000. Time Elapsed: 2418.682 s. Mean Reward: 0.366. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 2200000. Time Elapsed: 2430.033 s. Mean Reward: 0.364. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 2210000. Time Elapsed: 2441.549 s. Mean Reward: 0.344. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 2220000. Time Elapsed: 2453.132 s. Mean Reward: 0.322. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 2230000. Time Elapsed: 2464.193 s. Mean Reward: 0.434. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 2240000. Time Elapsed: 2474.943 s. Mean Reward: 0.373. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 2250000. Time Elapsed: 2486.149 s. Mean Reward: 0.350. Std of Reward: 0.553. Training.\n",
      "^C\n",
      "[INFO] Learning was interrupted. Please wait while the graph is generated.\n",
      "[INFO] Exported results/hallway_baseline1/Hallway/Hallway-2251504.onnx\n",
      "[INFO] Copied results/hallway_baseline1/Hallway/Hallway-2251504.onnx to results/hallway_baseline1/Hallway.onnx.\n"
     ]
    }
   ],
   "source": [
    "#kickoff hallway_baseline\n",
    "!mlagents-learn  /home/carolyn/demos/hallway/baseline_config.yaml --run-id=hallway_baseline1 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b962a1a-e493-4415-9d97-9d022aa7aeb6",
   "metadata": {},
   "source": [
    "### Hallway Optimal \n",
    "\n",
    "To run the below code, you would need to replace '/home/carolyn/demos/hallway/optimal_config.yaml' with the path to where you have saved the config/yaml files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04f3d921-57a7-4b34-abd1-353bf9740a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kills any old active config files which might be cached\n",
    "!pkill -9 mlagents-learn 2>/dev/null\n",
    "!sleep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379dc86c-7e7a-48c4-aa5d-223e1f50f89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 21:42:44.729113: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-13 21:42:44.803361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.30.0,\n",
      "  ml-agents-envs: 0.30.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.0.1+cu118\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: Hallway?team=0\n",
      "[WARNING] Deleting TensorBoard data events.out.tfevents.1765679951.CPitta83.5765.0 that was left over from a previous run.\n",
      "[INFO] Hyperparameters for behavior name Hallway: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t256\n",
      "\t  buffer_size:\t25600\n",
      "\t  learning_rate:\t0.0005\n",
      "\t  beta:\t0.04\n",
      "\t  epsilon:\t0.35\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t5\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\t\n",
      "\t    sequence_length:\t64\n",
      "\t    memory_size:\t128\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Hallway. Step: 10000. Time Elapsed: 16.432 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 20000. Time Elapsed: 23.514 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 30000. Time Elapsed: 35.376 s. Mean Reward: -0.922. Std of Reward: 0.311. Training.\n",
      "[INFO] Hallway. Step: 40000. Time Elapsed: 42.786 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 50000. Time Elapsed: 47.955 s. Mean Reward: -0.981. Std of Reward: 0.076. Training.\n",
      "[INFO] Hallway. Step: 60000. Time Elapsed: 59.669 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 70000. Time Elapsed: 66.893 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 80000. Time Elapsed: 76.991 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 90000. Time Elapsed: 83.570 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 100000. Time Elapsed: 91.206 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 110000. Time Elapsed: 102.586 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 120000. Time Elapsed: 108.219 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 130000. Time Elapsed: 119.449 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 140000. Time Elapsed: 126.252 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 150000. Time Elapsed: 133.314 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 160000. Time Elapsed: 143.467 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 170000. Time Elapsed: 150.442 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 180000. Time Elapsed: 162.009 s. Mean Reward: -0.976. Std of Reward: 0.092. Training.\n",
      "[INFO] Hallway. Step: 190000. Time Elapsed: 167.754 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 200000. Time Elapsed: 175.338 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 210000. Time Elapsed: 186.992 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Hallway. Step: 220000. Time Elapsed: 194.370 s. Mean Reward: -0.981. Std of Reward: 0.050. Training.\n",
      "[INFO] Hallway. Step: 230000. Time Elapsed: 205.012 s. Mean Reward: -1.000. Std of Reward: 0.001. Training.\n",
      "[INFO] Hallway. Step: 240000. Time Elapsed: 213.229 s. Mean Reward: -0.937. Std of Reward: 0.229. Training.\n",
      "[INFO] Hallway. Step: 250000. Time Elapsed: 221.443 s. Mean Reward: -1.000. Std of Reward: 0.001. Training.\n",
      "[INFO] Hallway. Step: 260000. Time Elapsed: 232.686 s. Mean Reward: -0.860. Std of Reward: 0.383. Training.\n",
      "[INFO] Hallway. Step: 270000. Time Elapsed: 240.350 s. Mean Reward: -0.948. Std of Reward: 0.230. Training.\n",
      "[INFO] Hallway. Step: 280000. Time Elapsed: 252.822 s. Mean Reward: -0.969. Std of Reward: 0.114. Training.\n",
      "[INFO] Hallway. Step: 290000. Time Elapsed: 258.973 s. Mean Reward: -1.000. Std of Reward: 0.001. Training.\n",
      "[INFO] Hallway. Step: 300000. Time Elapsed: 266.554 s. Mean Reward: -0.999. Std of Reward: 0.001. Training.\n",
      "[INFO] Hallway. Step: 310000. Time Elapsed: 279.144 s. Mean Reward: -0.935. Std of Reward: 0.212. Training.\n",
      "[INFO] Hallway. Step: 320000. Time Elapsed: 286.914 s. Mean Reward: -0.953. Std of Reward: 0.161. Training.\n",
      "[INFO] Hallway. Step: 330000. Time Elapsed: 297.447 s. Mean Reward: -0.941. Std of Reward: 0.162. Training.\n",
      "[INFO] Hallway. Step: 340000. Time Elapsed: 304.803 s. Mean Reward: -0.989. Std of Reward: 0.047. Training.\n",
      "[INFO] Hallway. Step: 350000. Time Elapsed: 311.608 s. Mean Reward: -0.991. Std of Reward: 0.036. Training.\n",
      "[INFO] Hallway. Step: 360000. Time Elapsed: 322.231 s. Mean Reward: -0.792. Std of Reward: 0.481. Training.\n",
      "[INFO] Hallway. Step: 370000. Time Elapsed: 330.082 s. Mean Reward: -0.646. Std of Reward: 0.618. Training.\n",
      "[INFO] Hallway. Step: 380000. Time Elapsed: 342.480 s. Mean Reward: -0.620. Std of Reward: 0.593. Training.\n",
      "[INFO] Hallway. Step: 390000. Time Elapsed: 349.680 s. Mean Reward: -0.770. Std of Reward: 0.490. Training.\n",
      "[INFO] Hallway. Step: 400000. Time Elapsed: 355.261 s. Mean Reward: -0.972. Std of Reward: 0.086. Training.\n",
      "[INFO] Hallway. Step: 410000. Time Elapsed: 369.592 s. Mean Reward: -0.613. Std of Reward: 0.614. Training.\n",
      "[INFO] Hallway. Step: 420000. Time Elapsed: 377.843 s. Mean Reward: -0.399. Std of Reward: 0.617. Training.\n",
      "[INFO] Hallway. Step: 430000. Time Elapsed: 389.021 s. Mean Reward: -0.606. Std of Reward: 0.573. Training.\n",
      "[INFO] Hallway. Step: 440000. Time Elapsed: 395.896 s. Mean Reward: -0.482. Std of Reward: 0.623. Training.\n",
      "[INFO] Hallway. Step: 450000. Time Elapsed: 403.489 s. Mean Reward: -0.472. Std of Reward: 0.589. Training.\n",
      "[INFO] Hallway. Step: 460000. Time Elapsed: 413.616 s. Mean Reward: -0.439. Std of Reward: 0.600. Training.\n",
      "[INFO] Hallway. Step: 470000. Time Elapsed: 421.150 s. Mean Reward: -0.274. Std of Reward: 0.684. Training.\n",
      "[INFO] Hallway. Step: 480000. Time Elapsed: 432.907 s. Mean Reward: -0.040. Std of Reward: 0.656. Training.\n",
      "[INFO] Hallway. Step: 490000. Time Elapsed: 440.147 s. Mean Reward: -0.153. Std of Reward: 0.597. Training.\n",
      "[INFO] Hallway. Step: 500000. Time Elapsed: 450.285 s. Mean Reward: -0.154. Std of Reward: 0.645. Training.\n",
      "/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-499985.onnx\n",
      "[INFO] Hallway. Step: 510000. Time Elapsed: 457.717 s. Mean Reward: 0.061. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 520000. Time Elapsed: 470.766 s. Mean Reward: 0.042. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 530000. Time Elapsed: 476.734 s. Mean Reward: 0.185. Std of Reward: 0.565. Training.\n",
      "[INFO] Hallway. Step: 540000. Time Elapsed: 488.794 s. Mean Reward: 0.249. Std of Reward: 0.563. Training.\n",
      "[INFO] Hallway. Step: 550000. Time Elapsed: 496.099 s. Mean Reward: 0.275. Std of Reward: 0.568. Training.\n",
      "[INFO] Hallway. Step: 560000. Time Elapsed: 507.547 s. Mean Reward: 0.245. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 570000. Time Elapsed: 514.618 s. Mean Reward: 0.156. Std of Reward: 0.543. Training.\n",
      "[INFO] Hallway. Step: 580000. Time Elapsed: 527.149 s. Mean Reward: 0.320. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 590000. Time Elapsed: 534.798 s. Mean Reward: 0.265. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 600000. Time Elapsed: 545.331 s. Mean Reward: 0.377. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 610000. Time Elapsed: 553.227 s. Mean Reward: 0.331. Std of Reward: 0.555. Training.\n",
      "[INFO] Hallway. Step: 620000. Time Elapsed: 565.439 s. Mean Reward: 0.249. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 630000. Time Elapsed: 571.534 s. Mean Reward: 0.290. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 640000. Time Elapsed: 583.690 s. Mean Reward: 0.351. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 650000. Time Elapsed: 596.038 s. Mean Reward: 0.361. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 660000. Time Elapsed: 602.157 s. Mean Reward: 0.374. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 670000. Time Elapsed: 614.713 s. Mean Reward: 0.309. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 680000. Time Elapsed: 622.331 s. Mean Reward: 0.315. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 690000. Time Elapsed: 633.148 s. Mean Reward: 0.322. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 700000. Time Elapsed: 640.964 s. Mean Reward: 0.329. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 710000. Time Elapsed: 652.572 s. Mean Reward: 0.288. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 720000. Time Elapsed: 663.122 s. Mean Reward: 0.353. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 730000. Time Elapsed: 670.711 s. Mean Reward: 0.291. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 740000. Time Elapsed: 683.120 s. Mean Reward: 0.328. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 750000. Time Elapsed: 689.123 s. Mean Reward: 0.289. Std of Reward: 0.544. Training.\n",
      "[INFO] Hallway. Step: 760000. Time Elapsed: 701.535 s. Mean Reward: 0.379. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 770000. Time Elapsed: 709.671 s. Mean Reward: 0.348. Std of Reward: 0.556. Training.\n",
      "[INFO] Hallway. Step: 780000. Time Elapsed: 720.708 s. Mean Reward: 0.304. Std of Reward: 0.545. Training.\n",
      "[INFO] Hallway. Step: 790000. Time Elapsed: 733.110 s. Mean Reward: 0.323. Std of Reward: 0.554. Training.\n",
      "[INFO] Hallway. Step: 800000. Time Elapsed: 740.665 s. Mean Reward: 0.392. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 810000. Time Elapsed: 751.335 s. Mean Reward: 0.413. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 820000. Time Elapsed: 759.427 s. Mean Reward: 0.370. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 830000. Time Elapsed: 771.837 s. Mean Reward: 0.405. Std of Reward: 0.546. Training.\n",
      "[INFO] Hallway. Step: 840000. Time Elapsed: 782.563 s. Mean Reward: 0.309. Std of Reward: 0.541. Training.\n",
      "[INFO] Hallway. Step: 850000. Time Elapsed: 790.908 s. Mean Reward: 0.363. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 860000. Time Elapsed: 803.231 s. Mean Reward: 0.364. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 870000. Time Elapsed: 811.513 s. Mean Reward: 0.419. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 880000. Time Elapsed: 822.488 s. Mean Reward: 0.416. Std of Reward: 0.547. Training.\n",
      "[INFO] Hallway. Step: 890000. Time Elapsed: 834.931 s. Mean Reward: 0.406. Std of Reward: 0.550. Training.\n",
      "[INFO] Hallway. Step: 900000. Time Elapsed: 842.552 s. Mean Reward: 0.384. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 910000. Time Elapsed: 852.648 s. Mean Reward: 0.405. Std of Reward: 0.549. Training.\n",
      "[INFO] Hallway. Step: 920000. Time Elapsed: 860.373 s. Mean Reward: 0.478. Std of Reward: 0.538. Training.\n",
      "[INFO] Hallway. Step: 930000. Time Elapsed: 873.047 s. Mean Reward: 0.368. Std of Reward: 0.551. Training.\n",
      "[INFO] Hallway. Step: 940000. Time Elapsed: 883.591 s. Mean Reward: 0.360. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 950000. Time Elapsed: 891.689 s. Mean Reward: 0.433. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 960000. Time Elapsed: 903.027 s. Mean Reward: 0.353. Std of Reward: 0.548. Training.\n",
      "[INFO] Hallway. Step: 970000. Time Elapsed: 911.339 s. Mean Reward: 0.417. Std of Reward: 0.552. Training.\n",
      "[INFO] Hallway. Step: 980000. Time Elapsed: 923.826 s. Mean Reward: 0.451. Std of Reward: 0.538. Training.\n",
      "[INFO] Hallway. Step: 990000. Time Elapsed: 934.938 s. Mean Reward: 0.472. Std of Reward: 0.542. Training.\n",
      "[INFO] Hallway. Step: 1000000. Time Elapsed: 942.628 s. Mean Reward: 0.449. Std of Reward: 0.545. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-999994.onnx\n",
      "[INFO] Hallway. Step: 1010000. Time Elapsed: 954.757 s. Mean Reward: 0.467. Std of Reward: 0.536. Training.\n",
      "[INFO] Hallway. Step: 1020000. Time Elapsed: 962.777 s. Mean Reward: 0.493. Std of Reward: 0.528. Training.\n",
      "[INFO] Hallway. Step: 1030000. Time Elapsed: 973.304 s. Mean Reward: 0.502. Std of Reward: 0.525. Training.\n",
      "[INFO] Hallway. Step: 1040000. Time Elapsed: 981.319 s. Mean Reward: 0.509. Std of Reward: 0.527. Training.\n",
      "[INFO] Hallway. Step: 1050000. Time Elapsed: 993.850 s. Mean Reward: 0.504. Std of Reward: 0.532. Training.\n",
      "[INFO] Hallway. Step: 1060000. Time Elapsed: 1004.627 s. Mean Reward: 0.519. Std of Reward: 0.527. Training.\n",
      "[INFO] Hallway. Step: 1070000. Time Elapsed: 1012.500 s. Mean Reward: 0.590. Std of Reward: 0.498. Training.\n",
      "[INFO] Hallway. Step: 1080000. Time Elapsed: 1024.700 s. Mean Reward: 0.531. Std of Reward: 0.517. Training.\n",
      "[INFO] Hallway. Step: 1090000. Time Elapsed: 1031.162 s. Mean Reward: 0.573. Std of Reward: 0.508. Training.\n",
      "[INFO] Hallway. Step: 1100000. Time Elapsed: 1043.487 s. Mean Reward: 0.595. Std of Reward: 0.499. Training.\n",
      "[INFO] Hallway. Step: 1110000. Time Elapsed: 1055.688 s. Mean Reward: 0.639. Std of Reward: 0.472. Training.\n",
      "[INFO] Hallway. Step: 1120000. Time Elapsed: 1061.651 s. Mean Reward: 0.608. Std of Reward: 0.490. Training.\n",
      "[INFO] Hallway. Step: 1130000. Time Elapsed: 1074.136 s. Mean Reward: 0.574. Std of Reward: 0.517. Training.\n",
      "[INFO] Hallway. Step: 1140000. Time Elapsed: 1082.117 s. Mean Reward: 0.559. Std of Reward: 0.521. Training.\n",
      "[INFO] Hallway. Step: 1150000. Time Elapsed: 1092.975 s. Mean Reward: 0.668. Std of Reward: 0.461. Training.\n",
      "[INFO] Hallway. Step: 1160000. Time Elapsed: 1105.687 s. Mean Reward: 0.637. Std of Reward: 0.482. Training.\n",
      "[INFO] Hallway. Step: 1170000. Time Elapsed: 1113.367 s. Mean Reward: 0.619. Std of Reward: 0.494. Training.\n",
      "[INFO] Hallway. Step: 1180000. Time Elapsed: 1123.864 s. Mean Reward: 0.680. Std of Reward: 0.458. Training.\n",
      "[INFO] Hallway. Step: 1190000. Time Elapsed: 1131.657 s. Mean Reward: 0.689. Std of Reward: 0.437. Training.\n",
      "[INFO] Hallway. Step: 1200000. Time Elapsed: 1144.136 s. Mean Reward: 0.759. Std of Reward: 0.384. Training.\n",
      "[INFO] Hallway. Step: 1210000. Time Elapsed: 1150.721 s. Mean Reward: 0.813. Std of Reward: 0.303. Training.\n",
      "[INFO] Hallway. Step: 1220000. Time Elapsed: 1163.113 s. Mean Reward: 0.840. Std of Reward: 0.259. Training.\n",
      "[INFO] Hallway. Step: 1230000. Time Elapsed: 1176.195 s. Mean Reward: 0.741. Std of Reward: 0.401. Training.\n",
      "[INFO] Hallway. Step: 1240000. Time Elapsed: 1182.015 s. Mean Reward: 0.812. Std of Reward: 0.310. Training.\n",
      "[INFO] Hallway. Step: 1250000. Time Elapsed: 1194.330 s. Mean Reward: 0.776. Std of Reward: 0.357. Training.\n",
      "[INFO] Hallway. Step: 1260000. Time Elapsed: 1202.541 s. Mean Reward: 0.801. Std of Reward: 0.326. Training.\n",
      "[INFO] Hallway. Step: 1270000. Time Elapsed: 1212.882 s. Mean Reward: 0.865. Std of Reward: 0.208. Training.\n",
      "[INFO] Hallway. Step: 1280000. Time Elapsed: 1220.628 s. Mean Reward: 0.832. Std of Reward: 0.279. Training.\n",
      "[INFO] Hallway. Step: 1290000. Time Elapsed: 1232.996 s. Mean Reward: 0.851. Std of Reward: 0.255. Training.\n",
      "[INFO] Hallway. Step: 1300000. Time Elapsed: 1243.748 s. Mean Reward: 0.872. Std of Reward: 0.204. Training.\n",
      "[INFO] Hallway. Step: 1310000. Time Elapsed: 1251.674 s. Mean Reward: 0.862. Std of Reward: 0.236. Training.\n",
      "[INFO] Hallway. Step: 1320000. Time Elapsed: 1263.939 s. Mean Reward: 0.825. Std of Reward: 0.307. Training.\n",
      "[INFO] Hallway. Step: 1330000. Time Elapsed: 1271.926 s. Mean Reward: 0.859. Std of Reward: 0.239. Training.\n",
      "[INFO] Hallway. Step: 1340000. Time Elapsed: 1283.684 s. Mean Reward: 0.877. Std of Reward: 0.198. Training.\n",
      "[INFO] Hallway. Step: 1350000. Time Elapsed: 1293.621 s. Mean Reward: 0.867. Std of Reward: 0.232. Training.\n",
      "[INFO] Hallway. Step: 1360000. Time Elapsed: 1301.544 s. Mean Reward: 0.846. Std of Reward: 0.277. Training.\n",
      "[INFO] Hallway. Step: 1370000. Time Elapsed: 1313.848 s. Mean Reward: 0.897. Std of Reward: 0.145. Training.\n",
      "[INFO] Hallway. Step: 1380000. Time Elapsed: 1324.793 s. Mean Reward: 0.897. Std of Reward: 0.157. Training.\n",
      "[INFO] Hallway. Step: 1390000. Time Elapsed: 1332.063 s. Mean Reward: 0.903. Std of Reward: 0.126. Training.\n",
      "[INFO] Hallway. Step: 1400000. Time Elapsed: 1344.173 s. Mean Reward: 0.913. Std of Reward: 0.100. Training.\n",
      "[INFO] Hallway. Step: 1410000. Time Elapsed: 1355.368 s. Mean Reward: 0.908. Std of Reward: 0.122. Training.\n",
      "[INFO] Hallway. Step: 1420000. Time Elapsed: 1363.203 s. Mean Reward: 0.910. Std of Reward: 0.135. Training.\n",
      "[INFO] Hallway. Step: 1430000. Time Elapsed: 1375.871 s. Mean Reward: 0.919. Std of Reward: 0.098. Training.\n",
      "[INFO] Hallway. Step: 1440000. Time Elapsed: 1387.226 s. Mean Reward: 0.906. Std of Reward: 0.161. Training.\n",
      "[INFO] Hallway. Step: 1450000. Time Elapsed: 1394.900 s. Mean Reward: 0.916. Std of Reward: 0.124. Training.\n",
      "[INFO] Hallway. Step: 1460000. Time Elapsed: 1407.361 s. Mean Reward: 0.906. Std of Reward: 0.151. Training.\n",
      "[INFO] Hallway. Step: 1470000. Time Elapsed: 1418.520 s. Mean Reward: 0.904. Std of Reward: 0.161. Training.\n",
      "[INFO] Hallway. Step: 1480000. Time Elapsed: 1426.395 s. Mean Reward: 0.922. Std of Reward: 0.096. Training.\n",
      "[INFO] Hallway. Step: 1490000. Time Elapsed: 1439.164 s. Mean Reward: 0.923. Std of Reward: 0.095. Training.\n",
      "[INFO] Hallway. Step: 1500000. Time Elapsed: 1450.024 s. Mean Reward: 0.914. Std of Reward: 0.132. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-1499986.onnx\n",
      "[INFO] Hallway. Step: 1510000. Time Elapsed: 1458.114 s. Mean Reward: 0.925. Std of Reward: 0.068. Training.\n",
      "[INFO] Hallway. Step: 1520000. Time Elapsed: 1470.823 s. Mean Reward: 0.919. Std of Reward: 0.117. Training.\n",
      "[INFO] Hallway. Step: 1530000. Time Elapsed: 1481.621 s. Mean Reward: 0.911. Std of Reward: 0.148. Training.\n",
      "[INFO] Hallway. Step: 1540000. Time Elapsed: 1489.918 s. Mean Reward: 0.922. Std of Reward: 0.097. Training.\n",
      "[INFO] Hallway. Step: 1550000. Time Elapsed: 1501.249 s. Mean Reward: 0.927. Std of Reward: 0.069. Training.\n",
      "[INFO] Hallway. Step: 1560000. Time Elapsed: 1513.553 s. Mean Reward: 0.925. Std of Reward: 0.094. Training.\n",
      "[INFO] Hallway. Step: 1570000. Time Elapsed: 1526.397 s. Mean Reward: 0.922. Std of Reward: 0.117. Training.\n",
      "[INFO] Hallway. Step: 1580000. Time Elapsed: 1533.209 s. Mean Reward: 0.927. Std of Reward: 0.090. Training.\n",
      "[INFO] Hallway. Step: 1590000. Time Elapsed: 1545.472 s. Mean Reward: 0.909. Std of Reward: 0.160. Training.\n",
      "[INFO] Hallway. Step: 1600000. Time Elapsed: 1557.870 s. Mean Reward: 0.921. Std of Reward: 0.118. Training.\n",
      "[INFO] Hallway. Step: 1610000. Time Elapsed: 1569.217 s. Mean Reward: 0.930. Std of Reward: 0.070. Training.\n",
      "[INFO] Hallway. Step: 1620000. Time Elapsed: 1577.326 s. Mean Reward: 0.931. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1630000. Time Elapsed: 1590.227 s. Mean Reward: 0.932. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1640000. Time Elapsed: 1601.049 s. Mean Reward: 0.932. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 1650000. Time Elapsed: 1613.835 s. Mean Reward: 0.931. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 1660000. Time Elapsed: 1621.957 s. Mean Reward: 0.932. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1670000. Time Elapsed: 1633.074 s. Mean Reward: 0.932. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1680000. Time Elapsed: 1645.451 s. Mean Reward: 0.938. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 1690000. Time Elapsed: 1657.027 s. Mean Reward: 0.933. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1700000. Time Elapsed: 1664.876 s. Mean Reward: 0.931. Std of Reward: 0.067. Training.\n",
      "[INFO] Hallway. Step: 1710000. Time Elapsed: 1677.124 s. Mean Reward: 0.920. Std of Reward: 0.129. Training.\n",
      "[INFO] Hallway. Step: 1720000. Time Elapsed: 1688.476 s. Mean Reward: 0.915. Std of Reward: 0.154. Training.\n",
      "[INFO] Hallway. Step: 1730000. Time Elapsed: 1701.190 s. Mean Reward: 0.933. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 1740000. Time Elapsed: 1709.210 s. Mean Reward: 0.931. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 1750000. Time Elapsed: 1720.330 s. Mean Reward: 0.919. Std of Reward: 0.129. Training.\n",
      "[INFO] Hallway. Step: 1760000. Time Elapsed: 1732.659 s. Mean Reward: 0.927. Std of Reward: 0.109. Training.\n",
      "[INFO] Hallway. Step: 1770000. Time Elapsed: 1744.993 s. Mean Reward: 0.926. Std of Reward: 0.111. Training.\n",
      "[INFO] Hallway. Step: 1780000. Time Elapsed: 1751.861 s. Mean Reward: 0.923. Std of Reward: 0.125. Training.\n",
      "[INFO] Hallway. Step: 1790000. Time Elapsed: 1764.420 s. Mean Reward: 0.936. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 1800000. Time Elapsed: 1776.904 s. Mean Reward: 0.927. Std of Reward: 0.093. Training.\n",
      "[INFO] Hallway. Step: 1810000. Time Elapsed: 1788.215 s. Mean Reward: 0.925. Std of Reward: 0.111. Training.\n",
      "[INFO] Hallway. Step: 1820000. Time Elapsed: 1796.214 s. Mean Reward: 0.936. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 1830000. Time Elapsed: 1808.839 s. Mean Reward: 0.938. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 1840000. Time Elapsed: 1819.887 s. Mean Reward: 0.934. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1850000. Time Elapsed: 1832.344 s. Mean Reward: 0.935. Std of Reward: 0.064. Training.\n",
      "[INFO] Hallway. Step: 1860000. Time Elapsed: 1843.968 s. Mean Reward: 0.938. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 1870000. Time Elapsed: 1852.083 s. Mean Reward: 0.938. Std of Reward: 0.020. Training.\n",
      "[INFO] Hallway. Step: 1880000. Time Elapsed: 1864.752 s. Mean Reward: 0.937. Std of Reward: 0.065. Training.\n",
      "[INFO] Hallway. Step: 1890000. Time Elapsed: 1876.256 s. Mean Reward: 0.938. Std of Reward: 0.017. Training.\n",
      "[INFO] Hallway. Step: 1900000. Time Elapsed: 1889.062 s. Mean Reward: 0.935. Std of Reward: 0.067. Training.\n",
      "[INFO] Hallway. Step: 1910000. Time Elapsed: 1897.266 s. Mean Reward: 0.926. Std of Reward: 0.092. Training.\n",
      "[INFO] Hallway. Step: 1920000. Time Elapsed: 1908.376 s. Mean Reward: 0.938. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 1930000. Time Elapsed: 1920.989 s. Mean Reward: 0.935. Std of Reward: 0.067. Training.\n",
      "[INFO] Hallway. Step: 1940000. Time Elapsed: 1931.989 s. Mean Reward: 0.939. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 1950000. Time Elapsed: 1944.776 s. Mean Reward: 0.930. Std of Reward: 0.105. Training.\n",
      "[INFO] Hallway. Step: 1960000. Time Elapsed: 1952.932 s. Mean Reward: 0.935. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 1970000. Time Elapsed: 1964.202 s. Mean Reward: 0.938. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 1980000. Time Elapsed: 1976.992 s. Mean Reward: 0.936. Std of Reward: 0.070. Training.\n",
      "[INFO] Hallway. Step: 1990000. Time Elapsed: 1989.247 s. Mean Reward: 0.938. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2000000. Time Elapsed: 1999.960 s. Mean Reward: 0.935. Std of Reward: 0.064. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-1999979.onnx\n",
      "[INFO] Hallway. Step: 2010000. Time Elapsed: 2007.865 s. Mean Reward: 0.940. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2020000. Time Elapsed: 2020.083 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2030000. Time Elapsed: 2030.513 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2040000. Time Elapsed: 2043.105 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2050000. Time Elapsed: 2054.062 s. Mean Reward: 0.939. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2060000. Time Elapsed: 2063.599 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2070000. Time Elapsed: 2075.653 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2080000. Time Elapsed: 2086.407 s. Mean Reward: 0.941. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2090000. Time Elapsed: 2098.917 s. Mean Reward: 0.939. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2100000. Time Elapsed: 2111.493 s. Mean Reward: 0.938. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2110000. Time Elapsed: 2118.789 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2120000. Time Elapsed: 2130.833 s. Mean Reward: 0.939. Std of Reward: 0.018. Training.\n",
      "[INFO] Hallway. Step: 2130000. Time Elapsed: 2142.449 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2140000. Time Elapsed: 2152.456 s. Mean Reward: 0.939. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2150000. Time Elapsed: 2164.856 s. Mean Reward: 0.939. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2160000. Time Elapsed: 2172.652 s. Mean Reward: 0.918. Std of Reward: 0.106. Training.\n",
      "[INFO] Hallway. Step: 2170000. Time Elapsed: 2183.340 s. Mean Reward: 0.931. Std of Reward: 0.043. Training.\n",
      "[INFO] Hallway. Step: 2180000. Time Elapsed: 2196.284 s. Mean Reward: 0.935. Std of Reward: 0.064. Training.\n",
      "[INFO] Hallway. Step: 2190000. Time Elapsed: 2208.907 s. Mean Reward: 0.938. Std of Reward: 0.026. Training.\n",
      "[INFO] Hallway. Step: 2200000. Time Elapsed: 2215.720 s. Mean Reward: 0.938. Std of Reward: 0.017. Training.\n",
      "[INFO] Hallway. Step: 2210000. Time Elapsed: 2228.091 s. Mean Reward: 0.938. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2220000. Time Elapsed: 2239.642 s. Mean Reward: 0.939. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2230000. Time Elapsed: 2249.723 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2240000. Time Elapsed: 2261.915 s. Mean Reward: 0.939. Std of Reward: 0.018. Training.\n",
      "[INFO] Hallway. Step: 2250000. Time Elapsed: 2269.670 s. Mean Reward: 0.929. Std of Reward: 0.107. Training.\n",
      "[INFO] Hallway. Step: 2260000. Time Elapsed: 2279.775 s. Mean Reward: 0.940. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2270000. Time Elapsed: 2291.999 s. Mean Reward: 0.939. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2280000. Time Elapsed: 2302.492 s. Mean Reward: 0.933. Std of Reward: 0.086. Training.\n",
      "[INFO] Hallway. Step: 2290000. Time Elapsed: 2314.671 s. Mean Reward: 0.940. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2300000. Time Elapsed: 2322.480 s. Mean Reward: 0.935. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2310000. Time Elapsed: 2332.372 s. Mean Reward: 0.930. Std of Reward: 0.107. Training.\n",
      "[INFO] Hallway. Step: 2320000. Time Elapsed: 2345.153 s. Mean Reward: 0.937. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2330000. Time Elapsed: 2357.839 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2340000. Time Elapsed: 2368.521 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2350000. Time Elapsed: 2376.567 s. Mean Reward: 0.937. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 2360000. Time Elapsed: 2388.590 s. Mean Reward: 0.939. Std of Reward: 0.017. Training.\n",
      "[INFO] Hallway. Step: 2370000. Time Elapsed: 2398.645 s. Mean Reward: 0.938. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2380000. Time Elapsed: 2411.384 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2390000. Time Elapsed: 2423.392 s. Mean Reward: 0.941. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 2400000. Time Elapsed: 2433.886 s. Mean Reward: 0.940. Std of Reward: 0.020. Training.\n",
      "[INFO] Hallway. Step: 2410000. Time Elapsed: 2441.824 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2420000. Time Elapsed: 2453.895 s. Mean Reward: 0.940. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2430000. Time Elapsed: 2465.211 s. Mean Reward: 0.937. Std of Reward: 0.064. Training.\n",
      "[INFO] Hallway. Step: 2440000. Time Elapsed: 2478.648 s. Mean Reward: 0.938. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2450000. Time Elapsed: 2489.706 s. Mean Reward: 0.937. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2460000. Time Elapsed: 2497.579 s. Mean Reward: 0.938. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2470000. Time Elapsed: 2510.823 s. Mean Reward: 0.936. Std of Reward: 0.064. Training.\n",
      "[INFO] Hallway. Step: 2480000. Time Elapsed: 2522.417 s. Mean Reward: 0.937. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2490000. Time Elapsed: 2535.204 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2500000. Time Elapsed: 2546.113 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-2499981.onnx\n",
      "[INFO] Hallway. Step: 2510000. Time Elapsed: 2558.366 s. Mean Reward: 0.937. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2520000. Time Elapsed: 2566.134 s. Mean Reward: 0.942. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2530000. Time Elapsed: 2576.925 s. Mean Reward: 0.940. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2540000. Time Elapsed: 2589.346 s. Mean Reward: 0.941. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2550000. Time Elapsed: 2601.783 s. Mean Reward: 0.940. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2560000. Time Elapsed: 2612.851 s. Mean Reward: 0.934. Std of Reward: 0.087. Training.\n",
      "[INFO] Hallway. Step: 2570000. Time Elapsed: 2621.425 s. Mean Reward: 0.940. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2580000. Time Elapsed: 2634.366 s. Mean Reward: 0.939. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2590000. Time Elapsed: 2646.223 s. Mean Reward: 0.939. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2600000. Time Elapsed: 2659.314 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2610000. Time Elapsed: 2671.341 s. Mean Reward: 0.938. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 2620000. Time Elapsed: 2684.461 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2630000. Time Elapsed: 2693.133 s. Mean Reward: 0.938. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 2640000. Time Elapsed: 2704.879 s. Mean Reward: 0.940. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2650000. Time Elapsed: 2717.495 s. Mean Reward: 0.937. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2660000. Time Elapsed: 2729.771 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 2670000. Time Elapsed: 2741.971 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2680000. Time Elapsed: 2750.569 s. Mean Reward: 0.942. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2690000. Time Elapsed: 2762.108 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2700000. Time Elapsed: 2774.733 s. Mean Reward: 0.933. Std of Reward: 0.090. Training.\n",
      "[INFO] Hallway. Step: 2710000. Time Elapsed: 2788.092 s. Mean Reward: 0.939. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2720000. Time Elapsed: 2799.945 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2730000. Time Elapsed: 2813.255 s. Mean Reward: 0.941. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2740000. Time Elapsed: 2822.030 s. Mean Reward: 0.937. Std of Reward: 0.064. Training.\n",
      "[INFO] Hallway. Step: 2750000. Time Elapsed: 2833.986 s. Mean Reward: 0.936. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2760000. Time Elapsed: 2847.263 s. Mean Reward: 0.937. Std of Reward: 0.063. Training.\n",
      "[INFO] Hallway. Step: 2770000. Time Elapsed: 2859.072 s. Mean Reward: 0.939. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2780000. Time Elapsed: 2872.247 s. Mean Reward: 0.939. Std of Reward: 0.060. Training.\n",
      "[INFO] Hallway. Step: 2790000. Time Elapsed: 2881.151 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 2800000. Time Elapsed: 2892.479 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2810000. Time Elapsed: 2905.945 s. Mean Reward: 0.935. Std of Reward: 0.087. Training.\n",
      "[INFO] Hallway. Step: 2820000. Time Elapsed: 2917.136 s. Mean Reward: 0.940. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 2830000. Time Elapsed: 2929.282 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2840000. Time Elapsed: 2942.764 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2850000. Time Elapsed: 2949.759 s. Mean Reward: 0.942. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2860000. Time Elapsed: 2962.569 s. Mean Reward: 0.942. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2870000. Time Elapsed: 2975.665 s. Mean Reward: 0.941. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 2880000. Time Elapsed: 2986.879 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2890000. Time Elapsed: 2999.723 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2900000. Time Elapsed: 3010.698 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2910000. Time Elapsed: 3018.713 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2920000. Time Elapsed: 3030.977 s. Mean Reward: 0.940. Std of Reward: 0.022. Training.\n",
      "[INFO] Hallway. Step: 2930000. Time Elapsed: 3041.634 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2940000. Time Elapsed: 3054.278 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2950000. Time Elapsed: 3067.292 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 2960000. Time Elapsed: 3078.465 s. Mean Reward: 0.938. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 2970000. Time Elapsed: 3086.793 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 2980000. Time Elapsed: 3098.390 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 2990000. Time Elapsed: 3110.944 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3000000. Time Elapsed: 3123.909 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-2999986.onnx\n",
      "[INFO] Hallway. Step: 3010000. Time Elapsed: 3135.781 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3020000. Time Elapsed: 3148.196 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3030000. Time Elapsed: 3156.680 s. Mean Reward: 0.941. Std of Reward: 0.018. Training.\n",
      "[INFO] Hallway. Step: 3040000. Time Elapsed: 3167.634 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3050000. Time Elapsed: 3180.106 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3060000. Time Elapsed: 3191.329 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3070000. Time Elapsed: 3205.366 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3080000. Time Elapsed: 3218.310 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3090000. Time Elapsed: 3225.782 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3100000. Time Elapsed: 3237.469 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3110000. Time Elapsed: 3249.354 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3120000. Time Elapsed: 3260.093 s. Mean Reward: 0.941. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3130000. Time Elapsed: 3271.979 s. Mean Reward: 0.941. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3140000. Time Elapsed: 3282.474 s. Mean Reward: 0.941. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3150000. Time Elapsed: 3290.468 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3160000. Time Elapsed: 3302.342 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3170000. Time Elapsed: 3314.317 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3180000. Time Elapsed: 3325.020 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3190000. Time Elapsed: 3337.142 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3200000. Time Elapsed: 3347.766 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3210000. Time Elapsed: 3360.969 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3220000. Time Elapsed: 3368.915 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3230000. Time Elapsed: 3379.470 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3240000. Time Elapsed: 3391.750 s. Mean Reward: 0.943. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 3250000. Time Elapsed: 3404.073 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3260000. Time Elapsed: 3415.682 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3270000. Time Elapsed: 3429.165 s. Mean Reward: 0.939. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 3280000. Time Elapsed: 3437.235 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3290000. Time Elapsed: 3448.459 s. Mean Reward: 0.940. Std of Reward: 0.066. Training.\n",
      "[INFO] Hallway. Step: 3300000. Time Elapsed: 3461.027 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3310000. Time Elapsed: 3471.869 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3320000. Time Elapsed: 3484.601 s. Mean Reward: 0.941. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 3330000. Time Elapsed: 3497.615 s. Mean Reward: 0.939. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 3340000. Time Elapsed: 3504.529 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3350000. Time Elapsed: 3517.599 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3360000. Time Elapsed: 3529.065 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3370000. Time Elapsed: 3541.531 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3380000. Time Elapsed: 3554.230 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3390000. Time Elapsed: 3565.248 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3400000. Time Elapsed: 3573.179 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3410000. Time Elapsed: 3586.069 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3420000. Time Elapsed: 3597.669 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3430000. Time Elapsed: 3609.989 s. Mean Reward: 0.942. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 3440000. Time Elapsed: 3621.419 s. Mean Reward: 0.940. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 3450000. Time Elapsed: 3633.654 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3460000. Time Elapsed: 3645.560 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3470000. Time Elapsed: 3651.901 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3480000. Time Elapsed: 3663.741 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3490000. Time Elapsed: 3675.682 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3500000. Time Elapsed: 3686.066 s. Mean Reward: 0.939. Std of Reward: 0.061. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-3499983.onnx\n",
      "[INFO] Hallway. Step: 3510000. Time Elapsed: 3699.550 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3520000. Time Elapsed: 3715.998 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3530000. Time Elapsed: 3724.464 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3540000. Time Elapsed: 3737.828 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3550000. Time Elapsed: 3751.326 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3560000. Time Elapsed: 3765.119 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3570000. Time Elapsed: 3776.792 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3580000. Time Elapsed: 3789.914 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3590000. Time Elapsed: 3798.750 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3600000. Time Elapsed: 3809.923 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3610000. Time Elapsed: 3822.441 s. Mean Reward: 0.939. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 3620000. Time Elapsed: 3835.094 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3630000. Time Elapsed: 3845.637 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3640000. Time Elapsed: 3858.454 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3650000. Time Elapsed: 3869.673 s. Mean Reward: 0.940. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 3660000. Time Elapsed: 3877.746 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3670000. Time Elapsed: 3890.839 s. Mean Reward: 0.942. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3680000. Time Elapsed: 3902.097 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3690000. Time Elapsed: 3915.405 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3700000. Time Elapsed: 3926.814 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3710000. Time Elapsed: 3940.195 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3720000. Time Elapsed: 3949.265 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3730000. Time Elapsed: 3960.378 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3740000. Time Elapsed: 3973.125 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3750000. Time Elapsed: 3986.341 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3760000. Time Elapsed: 3997.645 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3770000. Time Elapsed: 4010.631 s. Mean Reward: 0.940. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 3780000. Time Elapsed: 4022.200 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3790000. Time Elapsed: 4030.189 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3800000. Time Elapsed: 4043.044 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3810000. Time Elapsed: 4054.559 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3820000. Time Elapsed: 4067.644 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3830000. Time Elapsed: 4080.778 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3840000. Time Elapsed: 4092.404 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3850000. Time Elapsed: 4100.988 s. Mean Reward: 0.943. Std of Reward: 0.015. Training.\n",
      "[INFO] Hallway. Step: 3860000. Time Elapsed: 4112.541 s. Mean Reward: 0.943. Std of Reward: 0.016. Training.\n",
      "[INFO] Hallway. Step: 3870000. Time Elapsed: 4126.324 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3880000. Time Elapsed: 4139.538 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3890000. Time Elapsed: 4150.933 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3900000. Time Elapsed: 4163.783 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3910000. Time Elapsed: 4175.509 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3920000. Time Elapsed: 4183.940 s. Mean Reward: 0.944. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3930000. Time Elapsed: 4196.884 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 3940000. Time Elapsed: 4207.331 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 3950000. Time Elapsed: 4219.830 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3960000. Time Elapsed: 4232.166 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3970000. Time Elapsed: 4242.900 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3980000. Time Elapsed: 4250.962 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 3990000. Time Elapsed: 4263.210 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4000000. Time Elapsed: 4273.844 s. Mean Reward: 0.943. Std of Reward: 0.014. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-3999997.onnx\n",
      "[INFO] Hallway. Step: 4010000. Time Elapsed: 4286.295 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4020000. Time Elapsed: 4296.969 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4030000. Time Elapsed: 4309.078 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4040000. Time Elapsed: 4322.108 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 4050000. Time Elapsed: 4328.888 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4060000. Time Elapsed: 4341.790 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4070000. Time Elapsed: 4354.581 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4080000. Time Elapsed: 4365.827 s. Mean Reward: 0.941. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 4090000. Time Elapsed: 4378.320 s. Mean Reward: 0.941. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 4100000. Time Elapsed: 4389.213 s. Mean Reward: 0.944. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 4110000. Time Elapsed: 4402.300 s. Mean Reward: 0.940. Std of Reward: 0.061. Training.\n",
      "[INFO] Hallway. Step: 4120000. Time Elapsed: 4411.115 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4130000. Time Elapsed: 4421.590 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4140000. Time Elapsed: 4434.036 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4150000. Time Elapsed: 4446.338 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4160000. Time Elapsed: 4456.790 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4170000. Time Elapsed: 4469.604 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4180000. Time Elapsed: 4478.217 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4190000. Time Elapsed: 4489.689 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4200000. Time Elapsed: 4502.483 s. Mean Reward: 0.939. Std of Reward: 0.062. Training.\n",
      "[INFO] Hallway. Step: 4210000. Time Elapsed: 4513.746 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4220000. Time Elapsed: 4526.628 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4230000. Time Elapsed: 4539.490 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4240000. Time Elapsed: 4551.176 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4250000. Time Elapsed: 4559.523 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4260000. Time Elapsed: 4570.841 s. Mean Reward: 0.945. Std of Reward: 0.011. Training.\n",
      "[INFO] Hallway. Step: 4270000. Time Elapsed: 4583.690 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4280000. Time Elapsed: 4596.008 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4290000. Time Elapsed: 4607.913 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4300000. Time Elapsed: 4621.770 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4310000. Time Elapsed: 4632.999 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4320000. Time Elapsed: 4641.840 s. Mean Reward: 0.940. Std of Reward: 0.060. Training.\n",
      "[INFO] Hallway. Step: 4330000. Time Elapsed: 4654.273 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4340000. Time Elapsed: 4665.621 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4350000. Time Elapsed: 4678.558 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4360000. Time Elapsed: 4691.383 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4370000. Time Elapsed: 4702.128 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4380000. Time Elapsed: 4714.883 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4390000. Time Elapsed: 4723.525 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4400000. Time Elapsed: 4734.580 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4410000. Time Elapsed: 4748.376 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4420000. Time Elapsed: 4760.152 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4430000. Time Elapsed: 4773.241 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4440000. Time Elapsed: 4786.932 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4450000. Time Elapsed: 4793.668 s. Mean Reward: 0.942. Std of Reward: 0.020. Training.\n",
      "[INFO] Hallway. Step: 4460000. Time Elapsed: 4806.494 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4470000. Time Elapsed: 4818.207 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4480000. Time Elapsed: 4831.072 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4490000. Time Elapsed: 4844.631 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4500000. Time Elapsed: 4856.198 s. Mean Reward: 0.945. Std of Reward: 0.013. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-4499979.onnx\n",
      "[INFO] Hallway. Step: 4510000. Time Elapsed: 4869.383 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4520000. Time Elapsed: 4881.376 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4530000. Time Elapsed: 4889.875 s. Mean Reward: 0.944. Std of Reward: 0.011. Training.\n",
      "[INFO] Hallway. Step: 4540000. Time Elapsed: 4903.145 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4550000. Time Elapsed: 4914.278 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4560000. Time Elapsed: 4926.628 s. Mean Reward: 0.942. Std of Reward: 0.014. Training.\n",
      "[INFO] Hallway. Step: 4570000. Time Elapsed: 4939.307 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4580000. Time Elapsed: 4950.844 s. Mean Reward: 0.941. Std of Reward: 0.060. Training.\n",
      "[INFO] Hallway. Step: 4590000. Time Elapsed: 4959.454 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4600000. Time Elapsed: 4970.480 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4610000. Time Elapsed: 4983.511 s. Mean Reward: 0.945. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4620000. Time Elapsed: 4996.427 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4630000. Time Elapsed: 5007.218 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4640000. Time Elapsed: 5019.881 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4650000. Time Elapsed: 5030.919 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4660000. Time Elapsed: 5039.720 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4670000. Time Elapsed: 5052.409 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4680000. Time Elapsed: 5063.430 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4690000. Time Elapsed: 5076.285 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4700000. Time Elapsed: 5089.090 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4710000. Time Elapsed: 5100.754 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4720000. Time Elapsed: 5113.753 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4730000. Time Elapsed: 5122.586 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4740000. Time Elapsed: 5133.823 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4750000. Time Elapsed: 5146.990 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4760000. Time Elapsed: 5157.700 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4770000. Time Elapsed: 5170.841 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4780000. Time Elapsed: 5184.350 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4790000. Time Elapsed: 5195.919 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4800000. Time Elapsed: 5204.275 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4810000. Time Elapsed: 5216.098 s. Mean Reward: 0.945. Std of Reward: 0.011. Training.\n",
      "[INFO] Hallway. Step: 4820000. Time Elapsed: 5229.641 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4830000. Time Elapsed: 5242.686 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4840000. Time Elapsed: 5254.060 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4850000. Time Elapsed: 5267.085 s. Mean Reward: 0.945. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4860000. Time Elapsed: 5278.866 s. Mean Reward: 0.943. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4870000. Time Elapsed: 5287.600 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4880000. Time Elapsed: 5300.991 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4890000. Time Elapsed: 5312.684 s. Mean Reward: 0.944. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4900000. Time Elapsed: 5325.438 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4910000. Time Elapsed: 5337.953 s. Mean Reward: 0.943. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4920000. Time Elapsed: 5348.756 s. Mean Reward: 0.942. Std of Reward: 0.013. Training.\n",
      "[INFO] Hallway. Step: 4930000. Time Elapsed: 5361.070 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4940000. Time Elapsed: 5368.741 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4950000. Time Elapsed: 5379.483 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4960000. Time Elapsed: 5391.490 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4970000. Time Elapsed: 5401.987 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4980000. Time Elapsed: 5414.376 s. Mean Reward: 0.945. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 4990000. Time Elapsed: 5426.608 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "[INFO] Hallway. Step: 5000000. Time Elapsed: 5437.125 s. Mean Reward: 0.944. Std of Reward: 0.012. Training.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-4999981.onnx\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/hallway_optimal/Hallway/Hallway-5000008.onnx\n",
      "[INFO] Copied results/hallway_optimal/Hallway/Hallway-5000008.onnx to results/hallway_optimal/Hallway.onnx.\n"
     ]
    }
   ],
   "source": [
    "#kickoff hallway_optimal\n",
    "!mlagents-learn  /home/carolyn/demos/hallway/optimal_config.yaml --run-id=hallway_optimal --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35fa101-9b2a-4f8e-96b5-048d0402660c",
   "metadata": {},
   "source": [
    "### Pyramids Baseline Config Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447f9468-0b82-4340-9ff6-fc6fec351c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kills any old active config files which might be cached\n",
    "!pkill -9 mlagents-learn 2>/dev/null\n",
    "!sleep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b40f634-c308-41a6-b5f0-a94c57e83948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.30.0,\n",
      "  ml-agents-envs: 0.30.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 1.8.1+cu111\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: Pyramids?team=0\n",
      "[WARNING] Deleting TensorBoard data events.out.tfevents.1765692002.CPitta83.9775.0 that was left over from a previous run.\n",
      "2025-12-16 01:32:51.857241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
      "[INFO] Hyperparameters for behavior name Pyramids: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t  curiosity:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t0.02\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t256\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t    learning_rate:\t0.0003\n",
      "\t    encoding_size:\tNone\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tmax_steps:\t6000000\n",
      "\ttime_horizon:\t128\n",
      "\tsummary_freq:\t30000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Pyramids. Step: 30000. Time Elapsed: 48.211 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 60000. Time Elapsed: 82.478 s. Mean Reward: -0.926. Std of Reward: 0.421. Training.\n",
      "[INFO] Pyramids. Step: 90000. Time Elapsed: 117.225 s. Mean Reward: -0.786. Std of Reward: 0.669. Training.\n",
      "[INFO] Pyramids. Step: 120000. Time Elapsed: 152.252 s. Mean Reward: -0.864. Std of Reward: 0.527. Training.\n",
      "[INFO] Pyramids. Step: 150000. Time Elapsed: 187.476 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 180000. Time Elapsed: 221.186 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 210000. Time Elapsed: 255.729 s. Mean Reward: -0.937. Std of Reward: 0.352. Training.\n",
      "[INFO] Pyramids. Step: 240000. Time Elapsed: 291.225 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 270000. Time Elapsed: 324.974 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 300000. Time Elapsed: 360.813 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 330000. Time Elapsed: 395.085 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 360000. Time Elapsed: 429.600 s. Mean Reward: -0.930. Std of Reward: 0.387. Training.\n",
      "[INFO] Pyramids. Step: 390000. Time Elapsed: 465.639 s. Mean Reward: -0.793. Std of Reward: 0.644. Training.\n",
      "[INFO] Pyramids. Step: 420000. Time Elapsed: 501.241 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 450000. Time Elapsed: 535.208 s. Mean Reward: -0.914. Std of Reward: 0.487. Training.\n",
      "[INFO] Pyramids. Step: 480000. Time Elapsed: 569.706 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-499877.onnx\n",
      "[INFO] Pyramids. Step: 510000. Time Elapsed: 605.305 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 540000. Time Elapsed: 641.810 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 570000. Time Elapsed: 677.915 s. Mean Reward: -0.902. Std of Reward: 0.519. Training.\n",
      "[INFO] Pyramids. Step: 600000. Time Elapsed: 712.548 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 630000. Time Elapsed: 749.074 s. Mean Reward: -0.917. Std of Reward: 0.468. Training.\n",
      "[INFO] Pyramids. Step: 660000. Time Elapsed: 784.558 s. Mean Reward: -0.931. Std of Reward: 0.376. Training.\n",
      "[INFO] Pyramids. Step: 690000. Time Elapsed: 820.266 s. Mean Reward: -0.769. Std of Reward: 0.731. Training.\n",
      "[INFO] Pyramids. Step: 720000. Time Elapsed: 855.306 s. Mean Reward: -0.870. Std of Reward: 0.501. Training.\n",
      "[INFO] Pyramids. Step: 750000. Time Elapsed: 892.043 s. Mean Reward: -0.812. Std of Reward: 0.607. Training.\n",
      "[INFO] Pyramids. Step: 780000. Time Elapsed: 927.883 s. Mean Reward: -0.856. Std of Reward: 0.548. Training.\n",
      "[INFO] Pyramids. Step: 810000. Time Elapsed: 962.616 s. Mean Reward: -0.860. Std of Reward: 0.544. Training.\n",
      "[INFO] Pyramids. Step: 840000. Time Elapsed: 998.580 s. Mean Reward: -0.930. Std of Reward: 0.374. Training.\n",
      "[INFO] Pyramids. Step: 870000. Time Elapsed: 1034.863 s. Mean Reward: -0.934. Std of Reward: 0.361. Training.\n",
      "[INFO] Pyramids. Step: 900000. Time Elapsed: 1070.575 s. Mean Reward: -0.789. Std of Reward: 0.656. Training.\n",
      "[INFO] Pyramids. Step: 930000. Time Elapsed: 1105.019 s. Mean Reward: -0.793. Std of Reward: 0.634. Training.\n",
      "[INFO] Pyramids. Step: 960000. Time Elapsed: 1140.881 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 990000. Time Elapsed: 1175.597 s. Mean Reward: -0.809. Std of Reward: 0.673. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-999915.onnx\n",
      "[INFO] Pyramids. Step: 1020000. Time Elapsed: 1210.807 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 1050000. Time Elapsed: 1246.648 s. Mean Reward: -0.923. Std of Reward: 0.416. Training.\n",
      "[INFO] Pyramids. Step: 1080000. Time Elapsed: 1282.997 s. Mean Reward: -0.723. Std of Reward: 0.734. Training.\n",
      "[INFO] Pyramids. Step: 1110000. Time Elapsed: 1319.408 s. Mean Reward: -0.704. Std of Reward: 0.800. Training.\n",
      "[INFO] Pyramids. Step: 1140000. Time Elapsed: 1355.825 s. Mean Reward: -0.574. Std of Reward: 0.937. Training.\n",
      "[INFO] Pyramids. Step: 1170000. Time Elapsed: 1391.879 s. Mean Reward: -0.265. Std of Reward: 1.114. Training.\n",
      "[INFO] Pyramids. Step: 1200000. Time Elapsed: 1428.176 s. Mean Reward: -0.588. Std of Reward: 0.877. Training.\n",
      "[INFO] Pyramids. Step: 1230000. Time Elapsed: 1464.454 s. Mean Reward: -0.573. Std of Reward: 0.892. Training.\n",
      "[INFO] Pyramids. Step: 1260000. Time Elapsed: 1500.487 s. Mean Reward: -0.628. Std of Reward: 0.867. Training.\n",
      "[INFO] Pyramids. Step: 1290000. Time Elapsed: 1535.565 s. Mean Reward: -0.771. Std of Reward: 0.693. Training.\n",
      "[INFO] Pyramids. Step: 1320000. Time Elapsed: 1569.910 s. Mean Reward: -0.710. Std of Reward: 0.740. Training.\n",
      "[INFO] Pyramids. Step: 1350000. Time Elapsed: 1605.448 s. Mean Reward: -0.675. Std of Reward: 0.833. Training.\n",
      "[INFO] Pyramids. Step: 1380000. Time Elapsed: 1642.329 s. Mean Reward: -0.411. Std of Reward: 1.006. Training.\n",
      "[INFO] Pyramids. Step: 1410000. Time Elapsed: 1678.610 s. Mean Reward: 0.028. Std of Reward: 1.188. Training.\n",
      "[INFO] Pyramids. Step: 1440000. Time Elapsed: 1715.025 s. Mean Reward: 0.260. Std of Reward: 1.196. Training.\n",
      "[INFO] Pyramids. Step: 1470000. Time Elapsed: 1751.695 s. Mean Reward: -0.056. Std of Reward: 1.202. Training.\n",
      "[INFO] Pyramids. Step: 1500000. Time Elapsed: 1788.989 s. Mean Reward: 0.245. Std of Reward: 1.224. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-1499921.onnx\n",
      "[INFO] Pyramids. Step: 1530000. Time Elapsed: 1826.014 s. Mean Reward: 0.659. Std of Reward: 1.201. Training.\n",
      "[INFO] Pyramids. Step: 1560000. Time Elapsed: 1893.479 s. Mean Reward: 0.366. Std of Reward: 1.248. Training.\n",
      "[INFO] Pyramids. Step: 1590000. Time Elapsed: 1967.164 s. Mean Reward: 0.488. Std of Reward: 1.271. Training.\n",
      "[INFO] Pyramids. Step: 1620000. Time Elapsed: 2040.533 s. Mean Reward: 0.458. Std of Reward: 1.219. Training.\n",
      "[INFO] Pyramids. Step: 1650000. Time Elapsed: 2113.864 s. Mean Reward: 0.516. Std of Reward: 1.212. Training.\n",
      "[INFO] Pyramids. Step: 1680000. Time Elapsed: 2186.584 s. Mean Reward: 0.692. Std of Reward: 1.208. Training.\n",
      "[INFO] Pyramids. Step: 1710000. Time Elapsed: 2259.800 s. Mean Reward: 0.689. Std of Reward: 1.207. Training.\n",
      "[INFO] Pyramids. Step: 1740000. Time Elapsed: 2333.734 s. Mean Reward: 0.870. Std of Reward: 1.042. Training.\n",
      "[INFO] Pyramids. Step: 1770000. Time Elapsed: 2409.412 s. Mean Reward: 1.230. Std of Reward: 0.903. Training.\n",
      "[INFO] Pyramids. Step: 1800000. Time Elapsed: 2486.538 s. Mean Reward: 1.162. Std of Reward: 0.975. Training.\n",
      "[INFO] Pyramids. Step: 1830000. Time Elapsed: 2566.254 s. Mean Reward: 1.248. Std of Reward: 0.849. Training.\n",
      "[INFO] Pyramids. Step: 1860000. Time Elapsed: 2644.131 s. Mean Reward: 1.390. Std of Reward: 0.679. Training.\n",
      "[INFO] Pyramids. Step: 1890000. Time Elapsed: 2722.089 s. Mean Reward: 1.214. Std of Reward: 0.855. Training.\n",
      "[INFO] Pyramids. Step: 1920000. Time Elapsed: 2800.144 s. Mean Reward: 1.345. Std of Reward: 0.788. Training.\n",
      "[INFO] Pyramids. Step: 1950000. Time Elapsed: 2880.289 s. Mean Reward: 1.494. Std of Reward: 0.623. Training.\n",
      "[INFO] Pyramids. Step: 1980000. Time Elapsed: 2959.952 s. Mean Reward: 1.413. Std of Reward: 0.795. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-1999960.onnx\n",
      "[INFO] Pyramids. Step: 2010000. Time Elapsed: 3042.037 s. Mean Reward: 1.576. Std of Reward: 0.534. Training.\n",
      "[INFO] Pyramids. Step: 2040000. Time Elapsed: 3123.811 s. Mean Reward: 1.532. Std of Reward: 0.640. Training.\n",
      "[INFO] Pyramids. Step: 2070000. Time Elapsed: 3205.890 s. Mean Reward: 1.579. Std of Reward: 0.532. Training.\n",
      "[INFO] Pyramids. Step: 2100000. Time Elapsed: 3286.177 s. Mean Reward: 1.573. Std of Reward: 0.530. Training.\n",
      "[INFO] Pyramids. Step: 2130000. Time Elapsed: 3368.982 s. Mean Reward: 1.582. Std of Reward: 0.579. Training.\n",
      "[INFO] Pyramids. Step: 2160000. Time Elapsed: 3452.803 s. Mean Reward: 1.661. Std of Reward: 0.414. Training.\n",
      "[INFO] Pyramids. Step: 2190000. Time Elapsed: 3535.146 s. Mean Reward: 1.648. Std of Reward: 0.478. Training.\n",
      "[INFO] Pyramids. Step: 2220000. Time Elapsed: 3618.008 s. Mean Reward: 1.638. Std of Reward: 0.443. Training.\n",
      "[INFO] Pyramids. Step: 2250000. Time Elapsed: 28842.313 s. Mean Reward: 1.585. Std of Reward: 0.579. Training.\n",
      "[INFO] Pyramids. Step: 2280000. Time Elapsed: 28911.773 s. Mean Reward: 1.690. Std of Reward: 0.313. Training.\n",
      "[INFO] Pyramids. Step: 2310000. Time Elapsed: 28958.683 s. Mean Reward: 1.570. Std of Reward: 0.585. Training.\n",
      "[INFO] Pyramids. Step: 2340000. Time Elapsed: 28998.096 s. Mean Reward: 1.645. Std of Reward: 0.426. Training.\n",
      "[INFO] Pyramids. Step: 2370000. Time Elapsed: 29037.886 s. Mean Reward: 1.720. Std of Reward: 0.140. Training.\n",
      "[INFO] Pyramids. Step: 2400000. Time Elapsed: 29076.714 s. Mean Reward: 1.635. Std of Reward: 0.433. Training.\n",
      "[INFO] Pyramids. Step: 2430000. Time Elapsed: 29118.358 s. Mean Reward: 1.639. Std of Reward: 0.425. Training.\n",
      "[INFO] Pyramids. Step: 2460000. Time Elapsed: 29159.502 s. Mean Reward: 1.724. Std of Reward: 0.298. Training.\n",
      "[INFO] Pyramids. Step: 2490000. Time Elapsed: 29198.922 s. Mean Reward: 1.659. Std of Reward: 0.332. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-2499975.onnx\n",
      "[INFO] Pyramids. Step: 2520000. Time Elapsed: 29238.599 s. Mean Reward: 1.702. Std of Reward: 0.308. Training.\n",
      "[INFO] Pyramids. Step: 2550000. Time Elapsed: 29279.073 s. Mean Reward: 1.696. Std of Reward: 0.311. Training.\n",
      "[INFO] Pyramids. Step: 2580000. Time Elapsed: 29320.772 s. Mean Reward: 1.745. Std of Reward: 0.145. Training.\n",
      "[INFO] Pyramids. Step: 2610000. Time Elapsed: 29360.442 s. Mean Reward: 1.721. Std of Reward: 0.144. Training.\n",
      "[INFO] Pyramids. Step: 2640000. Time Elapsed: 29401.628 s. Mean Reward: 1.729. Std of Reward: 0.288. Training.\n",
      "[INFO] Pyramids. Step: 2670000. Time Elapsed: 29443.150 s. Mean Reward: 1.744. Std of Reward: 0.142. Training.\n",
      "[INFO] Pyramids. Step: 2700000. Time Elapsed: 29483.559 s. Mean Reward: 1.718. Std of Reward: 0.374. Training.\n",
      "[INFO] Pyramids. Step: 2730000. Time Elapsed: 29523.788 s. Mean Reward: 1.626. Std of Reward: 0.499. Training.\n",
      "[INFO] Pyramids. Step: 2760000. Time Elapsed: 29564.137 s. Mean Reward: 1.697. Std of Reward: 0.383. Training.\n",
      "[INFO] Pyramids. Step: 2790000. Time Elapsed: 29604.701 s. Mean Reward: 1.730. Std of Reward: 0.280. Training.\n",
      "[INFO] Pyramids. Step: 2820000. Time Elapsed: 29644.200 s. Mean Reward: 1.747. Std of Reward: 0.120. Training.\n",
      "[INFO] Pyramids. Step: 2850000. Time Elapsed: 29685.790 s. Mean Reward: 1.706. Std of Reward: 0.377. Training.\n",
      "[INFO] Pyramids. Step: 2880000. Time Elapsed: 29726.181 s. Mean Reward: 1.741. Std of Reward: 0.132. Training.\n",
      "[INFO] Pyramids. Step: 2910000. Time Elapsed: 29766.081 s. Mean Reward: 1.748. Std of Reward: 0.145. Training.\n",
      "[INFO] Pyramids. Step: 2940000. Time Elapsed: 29807.034 s. Mean Reward: 1.759. Std of Reward: 0.140. Training.\n",
      "[INFO] Pyramids. Step: 2970000. Time Elapsed: 29846.976 s. Mean Reward: 1.732. Std of Reward: 0.299. Training.\n",
      "[INFO] Pyramids. Step: 3000000. Time Elapsed: 29886.851 s. Mean Reward: 1.717. Std of Reward: 0.310. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-2999998.onnx\n",
      "[INFO] Pyramids. Step: 3030000. Time Elapsed: 29927.967 s. Mean Reward: 1.738. Std of Reward: 0.290. Training.\n",
      "[INFO] Pyramids. Step: 3060000. Time Elapsed: 29968.846 s. Mean Reward: 1.748. Std of Reward: 0.286. Training.\n",
      "[INFO] Pyramids. Step: 3090000. Time Elapsed: 30009.647 s. Mean Reward: 1.691. Std of Reward: 0.445. Training.\n",
      "[INFO] Pyramids. Step: 3120000. Time Elapsed: 30050.529 s. Mean Reward: 1.755. Std of Reward: 0.131. Training.\n",
      "[INFO] Pyramids. Step: 3150000. Time Elapsed: 30091.611 s. Mean Reward: 1.737. Std of Reward: 0.364. Training.\n",
      "[INFO] Pyramids. Step: 3180000. Time Elapsed: 30133.111 s. Mean Reward: 1.750. Std of Reward: 0.141. Training.\n",
      "[INFO] Pyramids. Step: 3210000. Time Elapsed: 30173.165 s. Mean Reward: 1.742. Std of Reward: 0.287. Training.\n",
      "[INFO] Pyramids. Step: 3240000. Time Elapsed: 30214.496 s. Mean Reward: 1.762. Std of Reward: 0.154. Training.\n",
      "[INFO] Pyramids. Step: 3270000. Time Elapsed: 30256.301 s. Mean Reward: 1.764. Std of Reward: 0.137. Training.\n",
      "[INFO] Pyramids. Step: 3300000. Time Elapsed: 30296.052 s. Mean Reward: 1.772. Std of Reward: 0.138. Training.\n",
      "[INFO] Pyramids. Step: 3330000. Time Elapsed: 30336.495 s. Mean Reward: 1.714. Std of Reward: 0.437. Training.\n",
      "[INFO] Pyramids. Step: 3360000. Time Elapsed: 30378.155 s. Mean Reward: 1.772. Std of Reward: 0.256. Training.\n",
      "[INFO] Pyramids. Step: 3390000. Time Elapsed: 30418.310 s. Mean Reward: 1.768. Std of Reward: 0.147. Training.\n",
      "[INFO] Pyramids. Step: 3420000. Time Elapsed: 30458.876 s. Mean Reward: 1.781. Std of Reward: 0.103. Training.\n",
      "[INFO] Pyramids. Step: 3450000. Time Elapsed: 30500.502 s. Mean Reward: 1.762. Std of Reward: 0.263. Training.\n",
      "[INFO] Pyramids. Step: 3480000. Time Elapsed: 30541.142 s. Mean Reward: 1.768. Std of Reward: 0.262. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-3499915.onnx\n",
      "[INFO] Pyramids. Step: 3510000. Time Elapsed: 30582.712 s. Mean Reward: 1.760. Std of Reward: 0.262. Training.\n",
      "[INFO] Pyramids. Step: 3540000. Time Elapsed: 30623.607 s. Mean Reward: 1.750. Std of Reward: 0.354. Training.\n",
      "[INFO] Pyramids. Step: 3570000. Time Elapsed: 30665.552 s. Mean Reward: 1.741. Std of Reward: 0.361. Training.\n",
      "[INFO] Pyramids. Step: 3600000. Time Elapsed: 30705.600 s. Mean Reward: 1.765. Std of Reward: 0.271. Training.\n",
      "[INFO] Pyramids. Step: 3630000. Time Elapsed: 30748.640 s. Mean Reward: 1.781. Std of Reward: 0.254. Training.\n",
      "[INFO] Pyramids. Step: 3660000. Time Elapsed: 30789.578 s. Mean Reward: 1.709. Std of Reward: 0.386. Training.\n",
      "[INFO] Pyramids. Step: 3690000. Time Elapsed: 30830.782 s. Mean Reward: 1.758. Std of Reward: 0.267. Training.\n",
      "[INFO] Pyramids. Step: 3720000. Time Elapsed: 30876.847 s. Mean Reward: 1.775. Std of Reward: 0.260. Training.\n",
      "[INFO] Pyramids. Step: 3750000. Time Elapsed: 30923.231 s. Mean Reward: 1.787. Std of Reward: 0.249. Training.\n",
      "[INFO] Pyramids. Step: 3780000. Time Elapsed: 30970.162 s. Mean Reward: 1.799. Std of Reward: 0.108. Training.\n",
      "[INFO] Pyramids. Step: 3810000. Time Elapsed: 31015.688 s. Mean Reward: 1.743. Std of Reward: 0.280. Training.\n",
      "[INFO] Pyramids. Step: 3840000. Time Elapsed: 31062.759 s. Mean Reward: 1.791. Std of Reward: 0.119. Training.\n",
      "[INFO] Pyramids. Step: 3870000. Time Elapsed: 31108.978 s. Mean Reward: 1.736. Std of Reward: 0.356. Training.\n",
      "[INFO] Pyramids. Step: 3900000. Time Elapsed: 31154.884 s. Mean Reward: 1.737. Std of Reward: 0.362. Training.\n",
      "[INFO] Pyramids. Step: 3930000. Time Elapsed: 31200.794 s. Mean Reward: 1.782. Std of Reward: 0.259. Training.\n",
      "[INFO] Pyramids. Step: 3960000. Time Elapsed: 31247.871 s. Mean Reward: 1.756. Std of Reward: 0.345. Training.\n",
      "[INFO] Pyramids. Step: 3990000. Time Elapsed: 31294.286 s. Mean Reward: 1.772. Std of Reward: 0.269. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-3999913.onnx\n",
      "[INFO] Pyramids. Step: 4020000. Time Elapsed: 31341.005 s. Mean Reward: 1.760. Std of Reward: 0.345. Training.\n",
      "[INFO] Pyramids. Step: 4050000. Time Elapsed: 31386.434 s. Mean Reward: 1.745. Std of Reward: 0.362. Training.\n",
      "[INFO] Pyramids. Step: 4080000. Time Elapsed: 31432.435 s. Mean Reward: 1.751. Std of Reward: 0.283. Training.\n",
      "[INFO] Pyramids. Step: 4110000. Time Elapsed: 31478.581 s. Mean Reward: 1.762. Std of Reward: 0.342. Training.\n",
      "[INFO] Pyramids. Step: 4140000. Time Elapsed: 31526.633 s. Mean Reward: 1.784. Std of Reward: 0.114. Training.\n",
      "[INFO] Pyramids. Step: 4170000. Time Elapsed: 31572.559 s. Mean Reward: 1.738. Std of Reward: 0.370. Training.\n",
      "[INFO] Pyramids. Step: 4200000. Time Elapsed: 31619.848 s. Mean Reward: 1.802. Std of Reward: 0.103. Training.\n",
      "[INFO] Pyramids. Step: 4230000. Time Elapsed: 31666.654 s. Mean Reward: 1.787. Std of Reward: 0.133. Training.\n",
      "[INFO] Pyramids. Step: 4260000. Time Elapsed: 31713.577 s. Mean Reward: 1.778. Std of Reward: 0.256. Training.\n",
      "[INFO] Pyramids. Step: 4290000. Time Elapsed: 31758.466 s. Mean Reward: 1.712. Std of Reward: 0.495. Training.\n",
      "[INFO] Pyramids. Step: 4320000. Time Elapsed: 31805.689 s. Mean Reward: 1.806. Std of Reward: 0.113. Training.\n",
      "[INFO] Pyramids. Step: 4350000. Time Elapsed: 31851.915 s. Mean Reward: 1.783. Std of Reward: 0.123. Training.\n",
      "[INFO] Pyramids. Step: 4380000. Time Elapsed: 31897.618 s. Mean Reward: 1.758. Std of Reward: 0.271. Training.\n",
      "[INFO] Pyramids. Step: 4410000. Time Elapsed: 31943.815 s. Mean Reward: 1.731. Std of Reward: 0.375. Training.\n",
      "[INFO] Pyramids. Step: 4440000. Time Elapsed: 31989.721 s. Mean Reward: 1.786. Std of Reward: 0.251. Training.\n",
      "[INFO] Pyramids. Step: 4470000. Time Elapsed: 32036.571 s. Mean Reward: 1.763. Std of Reward: 0.266. Training.\n",
      "[INFO] Pyramids. Step: 4500000. Time Elapsed: 32082.759 s. Mean Reward: 1.770. Std of Reward: 0.270. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-4499953.onnx\n",
      "[INFO] Pyramids. Step: 4530000. Time Elapsed: 32130.122 s. Mean Reward: 1.746. Std of Reward: 0.362. Training.\n",
      "[INFO] Pyramids. Step: 4560000. Time Elapsed: 32175.979 s. Mean Reward: 1.776. Std of Reward: 0.261. Training.\n",
      "[INFO] Pyramids. Step: 4590000. Time Elapsed: 32222.152 s. Mean Reward: 1.747. Std of Reward: 0.355. Training.\n",
      "[INFO] Pyramids. Step: 4620000. Time Elapsed: 32267.445 s. Mean Reward: 1.722. Std of Reward: 0.478. Training.\n",
      "[INFO] Pyramids. Step: 4650000. Time Elapsed: 32313.163 s. Mean Reward: 1.747. Std of Reward: 0.362. Training.\n",
      "[INFO] Pyramids. Step: 4680000. Time Elapsed: 32359.422 s. Mean Reward: 1.799. Std of Reward: 0.120. Training.\n",
      "[INFO] Pyramids. Step: 4710000. Time Elapsed: 32404.842 s. Mean Reward: 1.704. Std of Reward: 0.509. Training.\n",
      "[INFO] Pyramids. Step: 4740000. Time Elapsed: 32450.143 s. Mean Reward: 1.707. Std of Reward: 0.530. Training.\n",
      "[INFO] Pyramids. Step: 4770000. Time Elapsed: 32496.775 s. Mean Reward: 1.777. Std of Reward: 0.260. Training.\n",
      "[INFO] Pyramids. Step: 4800000. Time Elapsed: 32543.676 s. Mean Reward: 1.803. Std of Reward: 0.098. Training.\n",
      "[INFO] Pyramids. Step: 4830000. Time Elapsed: 32590.948 s. Mean Reward: 1.768. Std of Reward: 0.346. Training.\n",
      "[INFO] Pyramids. Step: 4860000. Time Elapsed: 32636.078 s. Mean Reward: 1.781. Std of Reward: 0.258. Training.\n",
      "[INFO] Pyramids. Step: 4890000. Time Elapsed: 33031.917 s. Mean Reward: 1.787. Std of Reward: 0.247. Training.\n",
      "[INFO] Pyramids. Step: 4920000. Time Elapsed: 33076.162 s. Mean Reward: 1.802. Std of Reward: 0.142. Training.\n",
      "[INFO] Pyramids. Step: 4950000. Time Elapsed: 33121.990 s. Mean Reward: 1.813. Std of Reward: 0.078. Training.\n",
      "[INFO] Pyramids. Step: 4980000. Time Elapsed: 33164.463 s. Mean Reward: 1.737. Std of Reward: 0.421. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-4999983.onnx\n",
      "[INFO] Pyramids. Step: 5010000. Time Elapsed: 33208.605 s. Mean Reward: 1.790. Std of Reward: 0.250. Training.\n",
      "[INFO] Pyramids. Step: 5040000. Time Elapsed: 33251.136 s. Mean Reward: 1.766. Std of Reward: 0.346. Training.\n",
      "[INFO] Pyramids. Step: 5070000. Time Elapsed: 33297.566 s. Mean Reward: 1.783. Std of Reward: 0.249. Training.\n",
      "[INFO] Pyramids. Step: 5100000. Time Elapsed: 33339.973 s. Mean Reward: 1.748. Std of Reward: 0.351. Training.\n",
      "[INFO] Pyramids. Step: 5130000. Time Elapsed: 33385.888 s. Mean Reward: 1.810. Std of Reward: 0.083. Training.\n",
      "[INFO] Pyramids. Step: 5160000. Time Elapsed: 33430.046 s. Mean Reward: 1.796. Std of Reward: 0.243. Training.\n",
      "[INFO] Pyramids. Step: 5190000. Time Elapsed: 33474.913 s. Mean Reward: 1.802. Std of Reward: 0.111. Training.\n",
      "[INFO] Pyramids. Step: 5220000. Time Elapsed: 33518.458 s. Mean Reward: 1.758. Std of Reward: 0.348. Training.\n",
      "[INFO] Pyramids. Step: 5250000. Time Elapsed: 33561.860 s. Mean Reward: 1.796. Std of Reward: 0.245. Training.\n",
      "[INFO] Pyramids. Step: 5280000. Time Elapsed: 33605.860 s. Mean Reward: 1.785. Std of Reward: 0.258. Training.\n",
      "[INFO] Pyramids. Step: 5310000. Time Elapsed: 33648.703 s. Mean Reward: 1.743. Std of Reward: 0.367. Training.\n",
      "[INFO] Pyramids. Step: 5340000. Time Elapsed: 33689.251 s. Mean Reward: 1.788. Std of Reward: 0.253. Training.\n",
      "[INFO] Pyramids. Step: 5370000. Time Elapsed: 33731.714 s. Mean Reward: 1.791. Std of Reward: 0.122. Training.\n",
      "[INFO] Pyramids. Step: 5400000. Time Elapsed: 33775.702 s. Mean Reward: 1.777. Std of Reward: 0.265. Training.\n",
      "[INFO] Pyramids. Step: 5430000. Time Elapsed: 33816.622 s. Mean Reward: 1.762. Std of Reward: 0.340. Training.\n",
      "[INFO] Pyramids. Step: 5460000. Time Elapsed: 33858.945 s. Mean Reward: 1.801. Std of Reward: 0.110. Training.\n",
      "[INFO] Pyramids. Step: 5490000. Time Elapsed: 33900.543 s. Mean Reward: 1.787. Std of Reward: 0.120. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-5499917.onnx\n",
      "[INFO] Pyramids. Step: 5520000. Time Elapsed: 33941.107 s. Mean Reward: 1.813. Std of Reward: 0.095. Training.\n",
      "[INFO] Pyramids. Step: 5550000. Time Elapsed: 33983.474 s. Mean Reward: 1.814. Std of Reward: 0.091. Training.\n",
      "[INFO] Pyramids. Step: 5580000. Time Elapsed: 34026.001 s. Mean Reward: 1.794. Std of Reward: 0.243. Training.\n",
      "[INFO] Pyramids. Step: 5610000. Time Elapsed: 34067.537 s. Mean Reward: 1.796. Std of Reward: 0.245. Training.\n",
      "[INFO] Pyramids. Step: 5640000. Time Elapsed: 34110.019 s. Mean Reward: 1.799. Std of Reward: 0.239. Training.\n",
      "[INFO] Pyramids. Step: 5670000. Time Elapsed: 34151.556 s. Mean Reward: 1.801. Std of Reward: 0.108. Training.\n",
      "[INFO] Pyramids. Step: 5700000. Time Elapsed: 34191.650 s. Mean Reward: 1.759. Std of Reward: 0.353. Training.\n",
      "[INFO] Pyramids. Step: 5730000. Time Elapsed: 34234.831 s. Mean Reward: 1.790. Std of Reward: 0.248. Training.\n",
      "[INFO] Pyramids. Step: 5760000. Time Elapsed: 34275.964 s. Mean Reward: 1.714. Std of Reward: 0.492. Training.\n",
      "[INFO] Pyramids. Step: 5790000. Time Elapsed: 34316.660 s. Mean Reward: 1.805. Std of Reward: 0.108. Training.\n",
      "[INFO] Pyramids. Step: 5820000. Time Elapsed: 34359.220 s. Mean Reward: 1.814. Std of Reward: 0.092. Training.\n",
      "[INFO] Pyramids. Step: 5850000. Time Elapsed: 34399.664 s. Mean Reward: 1.797. Std of Reward: 0.125. Training.\n",
      "[INFO] Pyramids. Step: 5880000. Time Elapsed: 34442.197 s. Mean Reward: 1.785. Std of Reward: 0.252. Training.\n",
      "[INFO] Pyramids. Step: 5910000. Time Elapsed: 34484.271 s. Mean Reward: 1.790. Std of Reward: 0.249. Training.\n",
      "[INFO] Pyramids. Step: 5940000. Time Elapsed: 34524.358 s. Mean Reward: 1.782. Std of Reward: 0.251. Training.\n",
      "[INFO] Pyramids. Step: 5970000. Time Elapsed: 34567.590 s. Mean Reward: 1.810. Std of Reward: 0.100. Training.\n",
      "[INFO] Pyramids. Step: 6000000. Time Elapsed: 34609.352 s. Mean Reward: 1.812. Std of Reward: 0.116. Training.\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-5999899.onnx\n",
      "[INFO] Exported results/pyramids_baseline1/Pyramids/Pyramids-6000027.onnx\n",
      "[INFO] Copied results/pyramids_baseline1/Pyramids/Pyramids-6000027.onnx to results/pyramids_baseline1/Pyramids.onnx.\n"
     ]
    }
   ],
   "source": [
    "#kickoff pyramids optimal\n",
    "!mlagents-learn  /home/carolyn/demos/pyramids/baseline_config.yaml --run-id=pyramids_baseline1 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7bc21-5364-4cc4-87b7-ad55d5276ad1",
   "metadata": {},
   "source": [
    "### Pyramids Optimal Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ecc9a0-0c21-47ec-8326-50cd651a13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kills any old active config files which might be cached\n",
    "!pkill -f mlagents\n",
    "!sleep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108b3445-10b8-4c3d-aeaa-08651e2d55eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.30.0,\n",
      "  ml-agents-envs: 0.30.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 1.8.1+cu111\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: Pyramids?team=0\n",
      "[WARNING] Deleting TensorBoard data events.out.tfevents.1765931849.CPitta83.9587.0 that was left over from a previous run.\n",
      "2025-12-16 19:42:14.133628: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-16 19:42:14.178511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/carolyn/anaconda3/envs/unity-rl-env38/lib/python3.8/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
      "[INFO] Hyperparameters for behavior name Pyramids: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t256\n",
      "\t  buffer_size:\t5120\n",
      "\t  learning_rate:\t0.0004\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t4\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  curiosity:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t0.02\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t256\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t    learning_rate:\t0.0005\n",
      "\t    encoding_size:\tNone\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tmax_steps:\t7000000\n",
      "\ttime_horizon:\t128\n",
      "\tsummary_freq:\t30000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Pyramids. Step: 30000. Time Elapsed: 47.306 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 60000. Time Elapsed: 82.164 s. Mean Reward: -0.847. Std of Reward: 0.611. Training.\n",
      "[INFO] Pyramids. Step: 90000. Time Elapsed: 116.855 s. Mean Reward: -0.929. Std of Reward: 0.397. Training.\n",
      "[INFO] Pyramids. Step: 120000. Time Elapsed: 151.633 s. Mean Reward: -0.932. Std of Reward: 0.377. Training.\n",
      "[INFO] Pyramids. Step: 150000. Time Elapsed: 189.568 s. Mean Reward: -0.917. Std of Reward: 0.452. Training.\n",
      "[INFO] Pyramids. Step: 180000. Time Elapsed: 225.708 s. Mean Reward: -0.861. Std of Reward: 0.528. Training.\n",
      "[INFO] Pyramids. Step: 210000. Time Elapsed: 261.712 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Pyramids. Step: 240000. Time Elapsed: 297.569 s. Mean Reward: -0.858. Std of Reward: 0.548. Training.\n",
      "[INFO] Pyramids. Step: 270000. Time Elapsed: 332.335 s. Mean Reward: -0.907. Std of Reward: 0.454. Training.\n",
      "[INFO] Pyramids. Step: 300000. Time Elapsed: 369.597 s. Mean Reward: -0.619. Std of Reward: 0.874. Training.\n",
      "[INFO] Pyramids. Step: 330000. Time Elapsed: 406.992 s. Mean Reward: -0.769. Std of Reward: 0.717. Training.\n",
      "[INFO] Pyramids. Step: 360000. Time Elapsed: 442.057 s. Mean Reward: -0.839. Std of Reward: 0.635. Training.\n",
      "[INFO] Pyramids. Step: 390000. Time Elapsed: 482.217 s. Mean Reward: -0.855. Std of Reward: 0.560. Training.\n",
      "[INFO] Pyramids. Step: 420000. Time Elapsed: 522.979 s. Mean Reward: -0.670. Std of Reward: 0.827. Training.\n",
      "[INFO] Pyramids. Step: 450000. Time Elapsed: 560.761 s. Mean Reward: -0.850. Std of Reward: 0.572. Training.\n",
      "[INFO] Pyramids. Step: 480000. Time Elapsed: 597.934 s. Mean Reward: -0.774. Std of Reward: 0.706. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-499877.onnx\n",
      "[INFO] Pyramids. Step: 510000. Time Elapsed: 634.946 s. Mean Reward: -0.608. Std of Reward: 0.878. Training.\n",
      "[INFO] Pyramids. Step: 540000. Time Elapsed: 669.879 s. Mean Reward: -0.790. Std of Reward: 0.665. Training.\n",
      "[INFO] Pyramids. Step: 570000. Time Elapsed: 706.378 s. Mean Reward: -0.699. Std of Reward: 0.783. Training.\n",
      "[INFO] Pyramids. Step: 600000. Time Elapsed: 743.329 s. Mean Reward: -0.860. Std of Reward: 0.532. Training.\n",
      "[INFO] Pyramids. Step: 630000. Time Elapsed: 780.849 s. Mean Reward: -0.419. Std of Reward: 1.013. Training.\n",
      "[INFO] Pyramids. Step: 660000. Time Elapsed: 818.162 s. Mean Reward: -0.575. Std of Reward: 0.890. Training.\n",
      "[INFO] Pyramids. Step: 690000. Time Elapsed: 854.244 s. Mean Reward: -0.480. Std of Reward: 0.985. Training.\n",
      "[INFO] Pyramids. Step: 720000. Time Elapsed: 891.308 s. Mean Reward: -0.503. Std of Reward: 0.978. Training.\n",
      "[INFO] Pyramids. Step: 750000. Time Elapsed: 928.858 s. Mean Reward: -0.324. Std of Reward: 1.060. Training.\n",
      "[INFO] Pyramids. Step: 780000. Time Elapsed: 966.005 s. Mean Reward: -0.857. Std of Reward: 0.553. Training.\n",
      "[INFO] Pyramids. Step: 810000. Time Elapsed: 1002.019 s. Mean Reward: -0.841. Std of Reward: 0.616. Training.\n",
      "[INFO] Pyramids. Step: 840000. Time Elapsed: 1039.839 s. Mean Reward: -0.240. Std of Reward: 1.131. Training.\n",
      "[INFO] Pyramids. Step: 870000. Time Elapsed: 1077.495 s. Mean Reward: -0.107. Std of Reward: 1.194. Training.\n",
      "[INFO] Pyramids. Step: 900000. Time Elapsed: 1115.029 s. Mean Reward: -0.259. Std of Reward: 1.164. Training.\n",
      "[INFO] Pyramids. Step: 930000. Time Elapsed: 1151.828 s. Mean Reward: 0.125. Std of Reward: 1.221. Training.\n",
      "[INFO] Pyramids. Step: 960000. Time Elapsed: 1186.948 s. Mean Reward: 0.209. Std of Reward: 1.220. Training.\n",
      "[INFO] Pyramids. Step: 990000. Time Elapsed: 1224.407 s. Mean Reward: 0.200. Std of Reward: 1.242. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-999890.onnx\n",
      "[INFO] Pyramids. Step: 1020000. Time Elapsed: 1261.759 s. Mean Reward: 0.610. Std of Reward: 1.134. Training.\n",
      "[INFO] Pyramids. Step: 1050000. Time Elapsed: 1298.794 s. Mean Reward: 0.495. Std of Reward: 1.172. Training.\n",
      "[INFO] Pyramids. Step: 1080000. Time Elapsed: 1336.411 s. Mean Reward: 0.341. Std of Reward: 1.221. Training.\n",
      "[INFO] Pyramids. Step: 1110000. Time Elapsed: 1371.976 s. Mean Reward: 0.775. Std of Reward: 1.122. Training.\n",
      "[INFO] Pyramids. Step: 1140000. Time Elapsed: 1409.155 s. Mean Reward: 0.846. Std of Reward: 1.132. Training.\n",
      "[INFO] Pyramids. Step: 1170000. Time Elapsed: 1447.488 s. Mean Reward: 0.992. Std of Reward: 1.015. Training.\n",
      "[INFO] Pyramids. Step: 1200000. Time Elapsed: 1485.932 s. Mean Reward: 1.211. Std of Reward: 0.893. Training.\n",
      "[INFO] Pyramids. Step: 1230000. Time Elapsed: 1522.419 s. Mean Reward: 1.137. Std of Reward: 0.996. Training.\n",
      "[INFO] Pyramids. Step: 1260000. Time Elapsed: 1560.927 s. Mean Reward: 1.344. Std of Reward: 0.784. Training.\n",
      "[INFO] Pyramids. Step: 1290000. Time Elapsed: 1599.337 s. Mean Reward: 1.193. Std of Reward: 0.971. Training.\n",
      "[INFO] Pyramids. Step: 1320000. Time Elapsed: 1638.395 s. Mean Reward: 1.427. Std of Reward: 0.655. Training.\n",
      "[INFO] Pyramids. Step: 1350000. Time Elapsed: 1677.258 s. Mean Reward: 1.481. Std of Reward: 0.672. Training.\n",
      "[INFO] Pyramids. Step: 1380000. Time Elapsed: 1714.388 s. Mean Reward: 1.543. Std of Reward: 0.466. Training.\n",
      "[INFO] Pyramids. Step: 1410000. Time Elapsed: 1753.939 s. Mean Reward: 1.530. Std of Reward: 0.548. Training.\n",
      "[INFO] Pyramids. Step: 1440000. Time Elapsed: 1795.136 s. Mean Reward: 1.632. Std of Reward: 0.489. Training.\n",
      "[INFO] Pyramids. Step: 1470000. Time Elapsed: 1835.405 s. Mean Reward: 1.614. Std of Reward: 0.429. Training.\n",
      "[INFO] Pyramids. Step: 1500000. Time Elapsed: 1872.875 s. Mean Reward: 1.653. Std of Reward: 0.345. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-1499954.onnx\n",
      "[INFO] Pyramids. Step: 1530000. Time Elapsed: 1935.631 s. Mean Reward: 1.582. Std of Reward: 0.573. Training.\n",
      "[INFO] Pyramids. Step: 1560000. Time Elapsed: 2010.315 s. Mean Reward: 1.649. Std of Reward: 0.336. Training.\n",
      "[INFO] Pyramids. Step: 1590000. Time Elapsed: 2084.597 s. Mean Reward: 1.572. Std of Reward: 0.623. Training.\n",
      "[INFO] Pyramids. Step: 1620000. Time Elapsed: 2160.299 s. Mean Reward: 1.601. Std of Reward: 0.568. Training.\n",
      "[INFO] Pyramids. Step: 1650000. Time Elapsed: 2231.302 s. Mean Reward: 1.664. Std of Reward: 0.411. Training.\n",
      "[INFO] Pyramids. Step: 1680000. Time Elapsed: 2306.583 s. Mean Reward: 1.551. Std of Reward: 0.579. Training.\n",
      "[INFO] Pyramids. Step: 1710000. Time Elapsed: 2382.457 s. Mean Reward: 1.717. Std of Reward: 0.295. Training.\n",
      "[INFO] Pyramids. Step: 1740000. Time Elapsed: 2457.986 s. Mean Reward: 1.694. Std of Reward: 0.393. Training.\n",
      "[INFO] Pyramids. Step: 1770000. Time Elapsed: 2534.429 s. Mean Reward: 1.727. Std of Reward: 0.296. Training.\n",
      "[INFO] Pyramids. Step: 1800000. Time Elapsed: 2606.694 s. Mean Reward: 1.717. Std of Reward: 0.289. Training.\n",
      "[INFO] Pyramids. Step: 1830000. Time Elapsed: 2682.020 s. Mean Reward: 1.724. Std of Reward: 0.161. Training.\n",
      "[INFO] Pyramids. Step: 1860000. Time Elapsed: 2758.016 s. Mean Reward: 1.678. Std of Reward: 0.407. Training.\n",
      "[INFO] Pyramids. Step: 1890000. Time Elapsed: 2835.417 s. Mean Reward: 1.715. Std of Reward: 0.296. Training.\n",
      "[INFO] Pyramids. Step: 1920000. Time Elapsed: 2913.835 s. Mean Reward: 1.732. Std of Reward: 0.277. Training.\n",
      "[INFO] Pyramids. Step: 1950000. Time Elapsed: 2987.702 s. Mean Reward: 1.727. Std of Reward: 0.280. Training.\n",
      "[INFO] Pyramids. Step: 1980000. Time Elapsed: 3065.056 s. Mean Reward: 1.715. Std of Reward: 0.301. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-1999928.onnx\n",
      "[INFO] Pyramids. Step: 2010000. Time Elapsed: 3142.445 s. Mean Reward: 1.715. Std of Reward: 0.379. Training.\n",
      "[INFO] Pyramids. Step: 2040000. Time Elapsed: 3218.729 s. Mean Reward: 1.713. Std of Reward: 0.372. Training.\n",
      "[INFO] Pyramids. Step: 2070000. Time Elapsed: 3293.452 s. Mean Reward: 1.771. Std of Reward: 0.117. Training.\n",
      "[INFO] Pyramids. Step: 2100000. Time Elapsed: 3370.778 s. Mean Reward: 1.752. Std of Reward: 0.258. Training.\n",
      "[INFO] Pyramids. Step: 2130000. Time Elapsed: 3426.859 s. Mean Reward: 1.720. Std of Reward: 0.374. Training.\n",
      "[INFO] Pyramids. Step: 2160000. Time Elapsed: 3470.120 s. Mean Reward: 1.729. Std of Reward: 0.366. Training.\n",
      "[INFO] Pyramids. Step: 2190000. Time Elapsed: 3513.366 s. Mean Reward: 1.724. Std of Reward: 0.368. Training.\n",
      "[INFO] Pyramids. Step: 2220000. Time Elapsed: 3551.879 s. Mean Reward: 1.752. Std of Reward: 0.275. Training.\n",
      "[INFO] Pyramids. Step: 2250000. Time Elapsed: 3593.383 s. Mean Reward: 1.766. Std of Reward: 0.135. Training.\n",
      "[INFO] Pyramids. Step: 2280000. Time Elapsed: 3635.089 s. Mean Reward: 1.793. Std of Reward: 0.102. Training.\n",
      "[INFO] Pyramids. Step: 2310000. Time Elapsed: 3676.731 s. Mean Reward: 1.775. Std of Reward: 0.139. Training.\n",
      "[INFO] Pyramids. Step: 2340000. Time Elapsed: 3718.587 s. Mean Reward: 1.768. Std of Reward: 0.259. Training.\n",
      "[INFO] Pyramids. Step: 2370000. Time Elapsed: 3757.513 s. Mean Reward: 1.771. Std of Reward: 0.131. Training.\n",
      "[INFO] Pyramids. Step: 2400000. Time Elapsed: 3798.701 s. Mean Reward: 1.791. Std of Reward: 0.102. Training.\n",
      "[INFO] Pyramids. Step: 2430000. Time Elapsed: 3839.730 s. Mean Reward: 1.774. Std of Reward: 0.116. Training.\n",
      "[INFO] Pyramids. Step: 2460000. Time Elapsed: 3881.427 s. Mean Reward: 1.768. Std of Reward: 0.259. Training.\n",
      "[INFO] Pyramids. Step: 2490000. Time Elapsed: 3922.998 s. Mean Reward: 1.786. Std of Reward: 0.117. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-2499948.onnx\n",
      "[INFO] Pyramids. Step: 2520000. Time Elapsed: 3962.661 s. Mean Reward: 1.799. Std of Reward: 0.106. Training.\n",
      "[INFO] Pyramids. Step: 2550000. Time Elapsed: 4003.704 s. Mean Reward: 1.771. Std of Reward: 0.263. Training.\n",
      "[INFO] Pyramids. Step: 2580000. Time Elapsed: 4043.966 s. Mean Reward: 1.732. Std of Reward: 0.282. Training.\n",
      "[INFO] Pyramids. Step: 2610000. Time Elapsed: 4085.505 s. Mean Reward: 1.763. Std of Reward: 0.343. Training.\n",
      "[INFO] Pyramids. Step: 2640000. Time Elapsed: 4124.933 s. Mean Reward: 1.774. Std of Reward: 0.260. Training.\n",
      "[INFO] Pyramids. Step: 2670000. Time Elapsed: 4165.084 s. Mean Reward: 1.755. Std of Reward: 0.284. Training.\n",
      "[INFO] Pyramids. Step: 2700000. Time Elapsed: 4206.579 s. Mean Reward: 1.721. Std of Reward: 0.427. Training.\n",
      "[INFO] Pyramids. Step: 2730000. Time Elapsed: 4247.448 s. Mean Reward: 1.764. Std of Reward: 0.274. Training.\n",
      "[INFO] Pyramids. Step: 2760000. Time Elapsed: 4288.400 s. Mean Reward: 1.730. Std of Reward: 0.425. Training.\n",
      "[INFO] Pyramids. Step: 2790000. Time Elapsed: 4327.420 s. Mean Reward: 1.723. Std of Reward: 0.439. Training.\n",
      "[INFO] Pyramids. Step: 2820000. Time Elapsed: 4368.142 s. Mean Reward: 1.781. Std of Reward: 0.109. Training.\n",
      "[INFO] Pyramids. Step: 2850000. Time Elapsed: 4409.544 s. Mean Reward: 1.710. Std of Reward: 0.441. Training.\n",
      "[INFO] Pyramids. Step: 2880000. Time Elapsed: 4450.683 s. Mean Reward: 1.745. Std of Reward: 0.357. Training.\n",
      "[INFO] Pyramids. Step: 2910000. Time Elapsed: 4491.371 s. Mean Reward: 1.752. Std of Reward: 0.285. Training.\n",
      "[INFO] Pyramids. Step: 2940000. Time Elapsed: 4530.050 s. Mean Reward: 1.741. Std of Reward: 0.281. Training.\n",
      "[INFO] Pyramids. Step: 2970000. Time Elapsed: 4571.668 s. Mean Reward: 1.726. Std of Reward: 0.435. Training.\n",
      "[INFO] Pyramids. Step: 3000000. Time Elapsed: 4613.275 s. Mean Reward: 1.744. Std of Reward: 0.357. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-2999919.onnx\n",
      "[INFO] Pyramids. Step: 3030000. Time Elapsed: 4654.891 s. Mean Reward: 1.770. Std of Reward: 0.123. Training.\n",
      "[INFO] Pyramids. Step: 3060000. Time Elapsed: 4696.119 s. Mean Reward: 1.744. Std of Reward: 0.358. Training.\n",
      "[INFO] Pyramids. Step: 3090000. Time Elapsed: 4735.739 s. Mean Reward: 1.765. Std of Reward: 0.278. Training.\n",
      "[INFO] Pyramids. Step: 3120000. Time Elapsed: 4777.115 s. Mean Reward: 1.691. Std of Reward: 0.514. Training.\n",
      "[INFO] Pyramids. Step: 3150000. Time Elapsed: 4819.089 s. Mean Reward: 1.751. Std of Reward: 0.359. Training.\n",
      "[INFO] Pyramids. Step: 3180000. Time Elapsed: 4860.423 s. Mean Reward: 1.746. Std of Reward: 0.283. Training.\n",
      "[INFO] Pyramids. Step: 3210000. Time Elapsed: 4900.037 s. Mean Reward: 1.738. Std of Reward: 0.426. Training.\n",
      "[INFO] Pyramids. Step: 3240000. Time Elapsed: 4942.025 s. Mean Reward: 1.738. Std of Reward: 0.361. Training.\n",
      "[INFO] Pyramids. Step: 3270000. Time Elapsed: 4982.677 s. Mean Reward: 1.722. Std of Reward: 0.374. Training.\n",
      "[INFO] Pyramids. Step: 3300000. Time Elapsed: 5023.599 s. Mean Reward: 1.773. Std of Reward: 0.136. Training.\n",
      "[INFO] Pyramids. Step: 3330000. Time Elapsed: 5065.878 s. Mean Reward: 1.769. Std of Reward: 0.254. Training.\n",
      "[INFO] Pyramids. Step: 3360000. Time Elapsed: 5103.687 s. Mean Reward: 1.780. Std of Reward: 0.127. Training.\n",
      "[INFO] Pyramids. Step: 3390000. Time Elapsed: 5144.557 s. Mean Reward: 1.763. Std of Reward: 0.340. Training.\n",
      "[INFO] Pyramids. Step: 3420000. Time Elapsed: 5184.993 s. Mean Reward: 1.756. Std of Reward: 0.154. Training.\n",
      "[INFO] Pyramids. Step: 3450000. Time Elapsed: 5225.870 s. Mean Reward: 1.797. Std of Reward: 0.112. Training.\n",
      "[INFO] Pyramids. Step: 3480000. Time Elapsed: 5266.898 s. Mean Reward: 1.684. Std of Reward: 0.512. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-3499953.onnx\n",
      "[INFO] Pyramids. Step: 3510000. Time Elapsed: 5306.524 s. Mean Reward: 1.776. Std of Reward: 0.254. Training.\n",
      "[INFO] Pyramids. Step: 3540000. Time Elapsed: 5347.939 s. Mean Reward: 1.766. Std of Reward: 0.263. Training.\n",
      "[INFO] Pyramids. Step: 3570000. Time Elapsed: 5399.769 s. Mean Reward: 1.782. Std of Reward: 0.133. Training.\n",
      "[INFO] Pyramids. Step: 3600000. Time Elapsed: 5478.299 s. Mean Reward: 1.721. Std of Reward: 0.369. Training.\n",
      "[INFO] Pyramids. Step: 3630000. Time Elapsed: 5557.581 s. Mean Reward: 1.752. Std of Reward: 0.360. Training.\n",
      "[INFO] Pyramids. Step: 3660000. Time Elapsed: 5633.960 s. Mean Reward: 1.773. Std of Reward: 0.325. Training.\n",
      "[INFO] Pyramids. Step: 3690000. Time Elapsed: 5714.412 s. Mean Reward: 1.756. Std of Reward: 0.411. Training.\n",
      "[INFO] Pyramids. Step: 3720000. Time Elapsed: 5794.382 s. Mean Reward: 1.759. Std of Reward: 0.280. Training.\n",
      "[INFO] Pyramids. Step: 3750000. Time Elapsed: 5874.154 s. Mean Reward: 1.761. Std of Reward: 0.276. Training.\n",
      "[INFO] Pyramids. Step: 3780000. Time Elapsed: 5952.547 s. Mean Reward: 1.773. Std of Reward: 0.334. Training.\n",
      "[INFO] Pyramids. Step: 3810000. Time Elapsed: 6027.730 s. Mean Reward: 1.788. Std of Reward: 0.114. Training.\n",
      "[INFO] Pyramids. Step: 3840000. Time Elapsed: 6106.775 s. Mean Reward: 1.704. Std of Reward: 0.535. Training.\n",
      "[INFO] Pyramids. Step: 3870000. Time Elapsed: 6184.839 s. Mean Reward: 1.735. Std of Reward: 0.365. Training.\n",
      "[INFO] Pyramids. Step: 3900000. Time Elapsed: 6264.881 s. Mean Reward: 1.813. Std of Reward: 0.085. Training.\n",
      "[INFO] Pyramids. Step: 3930000. Time Elapsed: 6340.633 s. Mean Reward: 1.782. Std of Reward: 0.252. Training.\n",
      "[INFO] Pyramids. Step: 3960000. Time Elapsed: 6419.285 s. Mean Reward: 1.753. Std of Reward: 0.287. Training.\n",
      "[INFO] Pyramids. Step: 3990000. Time Elapsed: 6497.873 s. Mean Reward: 1.782. Std of Reward: 0.141. Training.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-3999909.onnx\n",
      "^C\n",
      "[INFO] Learning was interrupted. Please wait while the graph is generated.\n",
      "[INFO] Exported results/pyramids_optimal/Pyramids/Pyramids-4018679.onnx\n",
      "[INFO] Copied results/pyramids_optimal/Pyramids/Pyramids-4018679.onnx to results/pyramids_optimal/Pyramids.onnx.\n"
     ]
    }
   ],
   "source": [
    "#kickoff pyramids optimal\n",
    "!mlagents-learn  /home/carolyn/demos/pyramids/optimal_config.yaml --run-id=pyramids_optimal --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3040d15-419e-4ca8-b78c-ff69cb545905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
